Session Agenda:

1.Caching Abstraction && Implementation using Spring boot
2.Redis for caching,message bus,data base, streaming......


Caching:

What is cache / Caching?

In computing, a cache is a component that transparently stores data so that future requests
for that data can be served faster.

The data that is stored within a cache might be values that have been computed earlier or duplicates of original values that are stored elsewhere.

Before this, you need to understand one concept, called "IO".

IO - read and write.

Write:
  moving data into some place

Place:
 - In memory
 - Disk
 - Network Socket
 - Processors
 - External Storage devices.

IN Memory: Random access memory :RAM.
......................................
- Writing data into RAM.

Which is faster, but not durable.

Disk:
  -Writing data into hard disk.
Eg:
  file systems
     -Databases-RDBMS
Which is slow but durable.

Network Socket:
 -socket is entry and exit point of networks
 -apps write data into socket via os kernal, which intern transfer data to other machines 
  in the network.

-Processors
   you can store data inside cpu registers for faster access.

- External Storage devices
   -physical storage like pendrives,extrnal harddisk....
   -Cloud Storage.

Reading:
 -Reading requires more responsive- end user should able to get data very very faster.

Reads costs more when we talk to disk(file system,databases,remote storages) based data.

How to improve read performance?
................................

if any application / users reads the same data again and again, dont hit disk every time, rather make snapeshot of that data in first hit, keeps that "IN Memory(RAM) / CPU Register"
so that future requests served very faster : Caching

Real world examples:

 if application sends an sql query request to database engine.

-The database engine 
   -parses the query
   -Query Excution plan
   -Query will be compiled - binary image of that query
   -Query exection - Database engine will do sys call to disk
   -Read operation begins
   -Results are prepared
   -Send back to Client Applicaiton

imagine, if application repeats the same process again.

How to improve Network reads : WEB

If web clients ask some web documents such as html,pdf,image,json,xml to the webserver.

-webserver will do low level io calls-read

if web clients ask the same document again and again, we need to improve performance, so that 
HTTP protocals having feature called storing repeated content some where(IN Memory)-HTTP caching.
///////////////////////////////////////////////////////////////////////////////////////////

Hardwares :How to avoid reading data within hardware devices

-Hardware cache
A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average cost (time or energy) to access data from the main memory. A cache is a smaller, faster memory, located closer to a processor core, which stores copies of the data from frequently used main memory locations.
/////////////////////////////////////////////////////////////////////////////////////////////
             
          Caching is nothing but how to improve IO( Frequrent READ of same data) operation


Types of Caching:
................
Based on implemenentations

-hardward level caching
-software level caching
   -Disk cache -databases,filesystems....
   -Web cache - webservers,proxy servers, cdn
   -Memoization - Program level caching, to avoid code repationcycles(loop)
                  - languages -pythyon,groovy,javascript-most of the functional pl
   -Application level caching with caching components
         -Caching in Java Apps.
         -Spring framework abstracts away caching soultions in enterprise/micro services
          application.

-network level caching
   -protocal based caching-TCP
   -HTTP
   -SMTP.
............................................................................................

How to implement caching: Cache algorthims/Policy

caching is allabout io.

-write 
-read
-Replacement / Eviction.

Write Policys:
.............
 It defines how to interact with cache component/architecture, when application starts writing data.

1.Write Through
2.Write Around
3.Write Back


1.Write through pattern/policy:
...............................

1.When ever write request comes , write operation will be done in cache system.
2.From the Cache , data will be written to Database System.
3.Once Data is written in database successfully, acknowledgement will be sent to Client Application.

4.Application has to wait until the response come from cache(not suitable for blocking apps)
  (may be suitable for async /non blocking application).
5.It increases latency, since cache interacts with db,db interacts with cache and app.

2.Write around policy:
.......................

1.Applications write data to database directly
2.When read requests, Application hits Cache
3.If no data found in the cache first time, Cache loads data from Database into caching
  system
4.If data found in the cache , data will be returned from cache itself.

3.Write Back Policy:
...................

1.Application sends write requests to Cache System, once write is completed in Cache, Acknowledgement sent to Client Application.

There is background service, which starts writing data from Cache into Database Async

/////////////////////////////////////////////////////////////////////////////////////////

Read Policy:
...........
1.Cache Hit
2.Cache Miss


Cache Hit:
..........
Cache hit means the requested data already there in the cache.
This request can be served by simply reading the cache, which is comparatively faster
Hit happens , subsquent calls only, first time it wont happen.


Cache Miss:
...........

1.The data has to be recomputed or fetched from its original storage location

2.A cache miss occurs either
   2.1.Because the data was never placed in the cache,
   2.2 Because the data was removed (“evicted”) from the cache by either the caching system itself or an external application that specifically made that eviction request.

/////////////////////////////////////////////////////////////////////////////////////////////

Cache Replacement-Eviction Policy:
..................................

This is policy , implemented by cache providers in order to manage memory.

How to clear stale /unwanted /un used data from the cache system?
  This process of removing data from cache system is called "eviction".

How to evict?

-manual evication
-automatic evication.
  Systems like redis offers an alogorthims-TTL - Time to live.(how long data can be inside
  System, once timeout, data will be removed automatically.

In order to evit data from cache system, there are plent of algorthims.

1.Bélády's algorithm
2.First in first out (FIFO)
3.Last in first out (LIFO) or First in last out (FILO)
4.Least recently used (LRU)
5.Time aware least recently used (TLRU)
6.Most recently used (MRU)
8.Pseudo-LRU (PLRU)
9.Random replacement (RR)
10.Segmented LRU (SLRU)
12.Least-frequently used (LFU)
13.Least frequent recently used (LFRU)
14.LFU with dynamic aging (LFUDA)
15.Low inter-reference recency set (LIRS)
16.CLOCK-Pro
17.Adaptive replacement cache (ARC)
18.AdaptiveClimb (AC)
19.Clock with adaptive replacement (CAR)
20.Multi queue (MQ)
21.Pannier: Container-based caching algorithm for compound objects


Least recently used (LRU):
   Redis uses this alorthim.

////////////////////////////////////////////////////////////////////////////////////////////

Application Caching  Soultions and Implementation:
..................................................

Application caching provides, how to store data inside application.

Application caching can be classified into two types:
.....................................................

1.Local Cache
2.Distributed Cache

Both cache implementation will store data in side RAM Only.


1.Local Cache : (Cache System) 
 
 Cache is provided iniside application as "Data Structure".
 if you are working in java application , java provides a spec called jcache
JSR 107: JCACHE - Java Temporary Caching API

 IF you  are working in spring framework, Spring framework provides an abstraction
  "Caching Abstraction" : set of apis and annotations , developers start building caching system without worring about underlaying cache implemenation(systems-like memcache,redis,hazlecast....)


          "Cache data is maintained inside Application Process(JVM)"

Spring provides an data structure called "ConcurrentHashMapCache" 
  -it is map datastructure
  - used to store data inside app.



Note:

  In any caching system, data is stored in side data structure only : KEY-VALUE pair datastructure : Dictionary/HashMap/Map
   This is fundamental storage model of any caching system.
.............................................................................................

2.Distributed Cache /Data Grid

    Cache data is maintained outside application process(JVM).

///////////////////////////////////////////////////////////////////////////////////////////

Caching best practices:
.......................

Local Cache:
 -Part of application
 -easy to implement
 -very fast, no lantency.
-as application shuts down, no where data is persisted.
-it is diffcult in concurrency
-data cant be replicated
-heap size will increase , if you store more data.
-Avoid big heaps just for caching
-Big heap leads to long major GCs


Distributed Cache:
 -outside application process
 -it is easy to scale across clusters of nodes.
 -it is easy to make highly  available.
 -It is persisted-you can save data across time.
etc.......


Use a distributed cache for big amounts of data

Distributed caches implemented cache nodes.

Cache Nodes:

1.Hazelcast
2.Redis
3.memcached
4.Appache zoo keeper
5.Generic.
6.EhCache 2. x.
7.Infinispan
//////////////////////////////////////////////////////////////////////////////////////////////

Application Caching Implementation using Spring Boot caching Abstraction:
.........................................................................

1.Spring boot can support local and distributed cache providers
2.Spring boot offers abstraction apis to work with any cache providers without changing app
  code, you can switch any provider any time.
3.Spring boot uses cache starter packages.

Spring boot Caching Architecture:
.................................
     				       Application
				   (Caching Abstraction)
					   |
				      CacheManager
					   |
				---------------------------------- Cache Providers
				|  |   |  |                       |
	                       LocalCache / Distributed
				   |              |
			     ConcurrentHashMap	  Redis,MemCache,EHCach,Haelzcast......



Spring Application Setup and how to employ caching.
...................................................

Application Req:
 -It could be simple Databse CURD app
 -It could be complex microservice application.

App settings:

Lab Guide:

1.go to 
https://start.spring.io/

2.Add springweb,springdata,springcache dependencies

pom.xml

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-cache</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-jpa</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
  	     <dependency>
           	 <groupId>com.h2database</groupId>
            	<artifactId>h2</artifactId>
       	     </dependency>

2.create entity,Repository,Services,Rest End point.

Entity
Book.java
package com.example.entity;
import javax.persistence.*;
import java.io.Serializable;

@Entity
public class Book {
    @Id
    @GeneratedValue
    private long id;
    private String name;
    private String category;
    private String author;
    private String publisher;
    private String edition;

    public long getId() {
        return id;
    }

    public void setId(long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getCategory() {
        return category;
    }

    public void setCategory(String category) {
        this.category = category;
    }

    public String getAuthor() {
        return author;
    }

    public void setAuthor(String author) {
        this.author = author;
    }

    public String getPublisher() {
        return publisher;
    }

    public void setPublisher(String publisher) {
        this.publisher = publisher;
    }

    public String getEdition() {
        return edition;
    }

    public void setEdition(String edition) {
        this.edition = edition;
    }

    @Override
    public String toString() {
        return "Book{" +
                "id=" + id +
                ", name='" + name + '\'' +
                ", category='" + category + '\'' +
                ", author='" + author + '\'' +
                ", publisher='" + publisher + '\'' +
                ", edition='" + edition + '\'' +
                '}';
    }
}
.........................................................................................

JPA implemenation:
.................

package com.example.repo;
import com.example.entity.Book;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import javax.transaction.Transactional;

public interface BookRepository extends JpaRepository<Book, Long> {
    @Transactional
    @Modifying
    @Query("update Book u set u.name=?2 where u.id=?1")
    int updateAddress(long id, String name);
}
........................................................................................

Service Implemenation:


package com.example.service;


import com.example.entity.Book;

public interface BookService {
    Book addBook(Book book);

    Book updateBook(Book book);

    Book getBook(long id);

    String deleteBook(long id);
}

package com.example.service;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.stereotype.Service;

import java.util.Optional;

@Service
public class BookServiceImpl implements BookService {

    private static final Logger logger = LoggerFactory.getLogger(BookServiceImpl.class);
    @Autowired
    private BookRepository bookRepository;

    @Override
    public Book addBook(Book book) {
        logger.info("adding book with id - {}", book.getId());
        return bookRepository.save(book);
    }


    @Override
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }

    @Override
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

    @Override
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
}
..........................................................................................

Controller

package com.example.api;

import com.example.entity.Book;
import com.example.service.BookService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;


@RestController
public class BooksController {

    @Autowired
    private BookService bookService;

    @PostMapping("/book")
    public Book addBook(@RequestBody Book book) {
        return bookService.addBook(book);
    }

    @PutMapping("/book")
    public Book updateBook(@RequestBody Book book) {
        return bookService.updateBook(book);
    }

    @GetMapping("/book/{id}")
    public Book getBook(@PathVariable long id) {
        return bookService.getBook(id);
    }

    @DeleteMapping("/book/{id}")
    public String deleteBook(@PathVariable long id) {
        return bookService.deleteBook(id);
    }
}
...........................................................................................
Main Application with Data:

package com.example;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;

@SpringBootApplication
public class MycacheAppApplication {

    public static void main(String[] args) {
        SpringApplication.run(MycacheAppApplication.class, args);
    }

    @Bean
    CommandLineRunner runner(BookRepository bookRepository) {
        return args -> {
            Book book = null;
            for (int i = 0; i < 10; i++) {
                book = new Book();
                book.setAuthor("Author " + i);
                book.setCategory("Caching " + i);
                book.setEdition(i + "nd edition ");
                book.setName("Caching in Action " + i);
                book.setPublisher("my Publisher " + i);
                bookRepository.save(book);
            }
            bookRepository.findAll().forEach(System.out::println);

        };
    }
}
/////////////////////////////////////////////////////////////////////////////////////

Test:
http://localhost:8080/book/1

you will get book information

{
id: 1,
name: "Caching in Action 0",
category: "Caching 0",
author: "Author 0",
publisher: "my Publisher 0",
edition: "0nd edition "
}

 browser-----controller----service---repo---db

Again if hit the same book,http://localhost:8080/book/1

The flow will go like above
///////////////////////////////////////////////////////////////////////////////////////////

Caching integration:
....................

Declarative Annotation-based Caching

For caching declaration, Spring’s caching abstraction provides a set of Java annotations:

@EnableCaching - Enable caching behaviour to the application

@Cacheable: Triggers cache population.

@CacheEvict: Triggers cache eviction.

@CachePut: Updates the cache without interfering with the method execution.

@Caching: Regroups multiple cache operations to be applied on a method.

@CacheConfig: Shares some common cache-related settings at class-level.
...........................................................................................


@EnableCaching - Enable caching behaviour to the application

-Can be added at top level- in the Main program or
-Can be created a separate Configuration file where you can add.

Spring Boot CacheProvider:
...........................

Hope you can understand how spring boot works-AutoConfiguration

Caching Auto-configuration
The Spring Boot Framework simplifies the implementation of caching by auto-configuration support. 

It searches for the libraries and configuration-files in the classpath and initializes the required dependency beans at the time of application startup

The auto-configuration of caching includes the following steps:
***************************************************************
1.Add the annotation @EnableCaching in the configuration file.
2.Add the required caching libraries in the classpath.

Where to start?

1.Setup Project and open Project.

2.Goto Spring boot - external libs--->spring.boot.autoconfigure--->spring factories--search---cache auto configuration-- select that--press Ctrl+N -->CacheAutoConfiguration.
Again
 goto
  org.springframework.boot.autoconfigure.cache.
   you can find cache providers informations...

Cache Properties:
Redis
 spring.cache.redis.timetolive
 spring.cache.redis.keyPrefix

How selects provider:
.....................

Spring Boot tries to detect the following providers (in this order):

1.Generic
2.EhCache 2.x
3.Hazelcast
4.Infinispan
5.JCache (JSR-107)
6.Redis
7.Guava
8.Simple

It is also possible to force the cache provider to use via the spring.cache.type property.
if you want to setup cache provider in application.properties or application.yaml

 spring.cache.type =provider


eg:
EhCache 2.x

<dependency>  
<groupId>org.ehcache</groupId>  
<artifactId>ehcache</artifactId>  
</dependency>  


EhCache 2.x is used if a file named ehcache.xml can be found at the root of the classpath. If EhCache 2.x and such file is present it is used to bootstrap the cache manager. An alternate configuration file can be provide a well using:

spring.cache.ehcache.config=classpath:config/another-config.xml

Simple
If none of these options worked out, a simple implementation using ConcurrentHashMap as cache store is configured. This is the default if no caching library is present in your application.

Note : default is jdk concurrentHashMap only.

///////////////////////////////////////////////////////////////////////////////////////////

How and where caching features are applied.
...........................................

 Caching features are added on top of biz apis - find,update,delete


At its core, the cache abstraction applies caching to Java methods, thus reducing the number of executions based on the information available in the cache.

That is, each time a targeted method is invoked, the abstraction applies a caching behavior that checks whether the method has been already executed for the given arguments.

If it has been executed, the cached result is returned without having to execute the actual method.

 If the method has not been executed, then it is executed, and the result is cached and returned to the user so that, the next time the method is invoked the cached result is returned.

This way, expensive methods (whether CPU- or IO-bound) can be executed only once for a given set of parameters and the result reused without having to actually execute the method again

The caching logic is applied transparently without any interference to the invoker.

"This approach works only for methods that are guaranteed to return the same output (result) for a given input (or arguments) no matter how many times it is executed."

........................................................................................

Annotations overview:
.....................

@Cachable:
As the name implies, you can use @Cacheable to demarcate methods that are cacheable 
-that is, methods for which the result is stored in the cache so that, on subsequent invocations (with the same arguments), the value in the cache is returned without having to actually execute the method.

parameterize it with the name of the cache where the results would be stored.

eg:
@Cacheable("books")
public Book findBook(ISBN isbn) {...}

The findBook() call will first check the cache books before actually invoking the method and then caching the result.

-In the preceding snippet, the findBook method is associated with the cache named books.

-Each time the method is called, the cache is checked to see whether the invocation has already been executed and does not have to be repeated.

-While in most cases, only one cache is declared, the annotation lets multiple names be specified so that more than one cache is being use.

-. In this case, each of the caches is checked before executing the method — if at least one cache is hit, the associated value is returned.

"

Eg:
    @Override
    //now this method will executed only if cache miss, if cache hit, method wont be executed
    @Cacheable("books")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(key,value);

Multiple cach names:
...................
The following example uses @Cacheable on the findBook method:

@Cacheable({"books", "isbns"})
public Book findBook(ISBN isbn) {...}

In this case, if any of the caches contains the required result, the result is returned and the method is not invoked.

eg:
    @Override
    @Cacheable(cacheNames = {"books", "isbns"})
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

////////////////////////////////////////////////////////////////////////////////////////////

How Spring boot sends cached data to Cache Provider? How data is indentified in caching?

-You need unique indentification.

Key-Value Store:

 All cache implementation uses , key-value stores internally.
 Each invocation of a cached method needs to be translated into a suitable key for cache  access

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(key,value);


KeyGenerator:

-This is responsible for generating every key for each data item in the cache, which would be used to lookup the data item on retrieval.

-The default implementation here is the SimpleKeyGenerator – which uses the method parameters provided to generate a key

The default key generator

By default, SimpleKeyGenerator in the org.springframework.cache.interceptor package, an implementation of KeyGenerator interface, is used to generate the cache key

SimpleKeyGenerator evaluates parameters of the cache annotated methods (by @Cachable, @CachePut and @CacheEvict). If only one non-null param is existing, it returns the param itself, otherwise the below SimpleKey's toString() method is used for computing all params

@Override
public String toString() {  
    return getClass().getSimpleName() + " [" + StringUtils.arrayToCommaDelimitedString(this.params) + "]";
}

Default Key Generation

The caching abstraction uses a simple KeyGenerator based on the following algorithm.

-If no params are given, return SimpleKey.EMPTY.

-If only one param is given, return that instance.

-If more than one param is given, return a SimpleKey that contains all parameters


   @Cacheable("books")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(1,book);


Default Key Generation code

public class CustomKeyGenerator implements KeyGenerator {

 @Override
 public Object generate(Object target, Method method, Object...params) {
  return generateKey(params);
 }

 /**
  * Generate a key based on the specified parameters.
  */
 public static Object generateKey(Object...params) {
  if (params.length == 0) {
   return CustomCacheKey.EMPTY;
  }
  if (params.length == 1) {
   Object param = params[0];
   if (param != null && !param.getClass().isArray()) {
    return param;
   }
  }
  return new CustomCacheKey(params);
 }
}
////////////////////////////////////////////////////////////////////////////////////////////

/////////////////////////////////////////////////////////////////////////////////////////////

IS it Recommended to use default key generation ?

No!
Because it may cause unexpected key collisions.

Recommended use keys parameters:

The @Cacheable annotation lets you specify how the key
 is generated through its key attribute

@Cacheable(cacheNames="books", key="#isbn")
public Book findBook(ISBN isbn, boolean checkWarehouse, boolean includeUsed)

# - spring expression language syntax.
isbn - key reference. here we are using entire object as key.

Eg:

    @Cacheable(cacheNames = {"books"}, key = "#id")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

Note:
ISBN isbn and key="#isbn" should match.

@Cacheable(cacheNames="books", key="#isbn.rawNumber")
public Book findBook(ISBN isbn, boolean checkWarehouse, boolean includeUsed)
Here we are taking isbn.rawNumber which is one of the field value for cache.

////////////////////////////////////////////*********************////////////////////////////

Conditional Based Caching:
..........................

Use case:
 What if i dont want to cache every thing i mean , i need to cache only few values 
based on some condtion.

The cache annotations support such functionality through the condition parameter, which takes a SpEL expression that is evaluated to either true or false.
If true, the method is cached. If not, it

@Cacheable(cacheNames="book", condition="#name.length() < 32") 
public Book findBook(String name)

//conditional : cache only books whose id greater than 5
    @Override
    @Cacheable(cacheNames = "books", condition = "#id>5 ")
    public Book getBook(long id) {
        logger.info("fetching book from db" + id);
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Multi threading and caching:

 if  a  method is by multiple thread of execution , there might be inconsistency in data reterival.


Synchronized caching

In a multi-threaded environment, certain operations might be concurrently invoked for the same argument (typically on startup). By default, the cache abstraction does not lock anything and the same value may be computed several times, defeating the purpose of caching.

For those particular cases, the sync attribute can be used to instruct the underlying cache provider to lock the cache entry while the value is being computed. As a result, only one thread will be busy computing the value while the others are blocked until the entry is updated in the cache.

@Cacheable(cacheNames="foos", sync=true)
public Foo executeExpensiveOperation(String id) {...}

This is an optional feature and your favorite cache library may not support it. All CacheManager implementations provided by the core framework support it. Check the documentation of your cache provider for more details.
////////////////////////////////////////////////////////////////////////////////////////////

How to update Cache?
....................

In order to avoid inconsistency between database and cache during data updates in the database.

When ever we update database, we need to update cache provider also.

                                      update cache as well
                                          |
 Client---------PUT------------api-----service---Repo---db

@CachePut:
-When the cache needs to be updated without interfering with the method execution, you can use the @CachePut annotation.


  @Override
    @CachePut(cacheNames = "books", key = "#book.id")
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }
/////////////////////////////////////////////////////////////////////////////////////////////
How to evit data from cache?
 -Via code
 -automatic

When ever we remove record from databse , we need to remove key from cache also.

                                      Delete from cache as well
                                          |
 Client---------DELTE------------api-----service---Repo---db

How to remove cache Entries?

@CacheEvict annotation:
.......................
The cache abstraction allows not just population of a cache store but also eviction

This process is useful for removing stale or unused data from the cache.

 Opposed to @Cacheable, annotation @CacheEvict demarcates methods that perform cache eviction, that is methods that act as triggers for removing data from the cache. 

Just like its sibling, @CacheEvict requires specifying one (or multiple) caches that are affected by the action, allows a custom cache and key resolution or a condition to be specified but in addition, features an extra parameter allEntries which indicates whether a cache-wide eviction needs to be performed rather then just an entry one (based on the key):

@CacheEvict(cacheNames="books", allEntries=true)
public void loadBooks(InputStream batch)


    @Override
    @CacheEvict(cacheNames = "books", key = "#id" ,allEntries = true)
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
////////////////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////////////////

@Caching:

Use case , what if i want to apply different caching on single method
like having two different CacheEvit Policy.

Sometimes, multiple annotations of the same type (such as @CacheEvict or @CachePut) need to be specified — for example, because the condition or the key expression is different between different caches. @Caching lets multiple nested @Cacheable, @CachePut, and @CacheEvict annotations be used on the same method. The following example uses two @CacheEvict annotations


@Caching(evict = { @CacheEvict("primary"), @CacheEvict(cacheNames="secondary", key="#p0") })
public Book importBooks(String deposit, Date date)

//////////////////////////////////////////////////////////////////////////////////////////

@CacheConfig annotation

So far we have seen that caching operations offered many customization options and these can be set on an operation basis. 

However, some of the customization options can be tedious to configure if they apply to all operations of the class. For instance, specifying the name of the cache to use for every cache operation of the class could be replaced by a single class-level definition.
This is where @CacheConfig comes into play.

@CacheConfig("books")
public class BookRepositoryImpl implements BookRepository {

    @Cacheable
    public Book findBook(ISBN isbn) {...}
}

eg:
package com.example.service;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cache.annotation.CacheConfig;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.cache.annotation.CachePut;
import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Service;

import java.util.Optional;

@Service
@CacheConfig(cacheNames = "books")
public class BookServiceImpl implements BookService {

    private static final Logger logger = LoggerFactory.getLogger(BookServiceImpl.class);
    @Autowired
    private BookRepository bookRepository;

    @Override
    public Book addBook(Book book) {
        logger.info("adding book with id - {}", book.getId());
        return bookRepository.save(book);
    }


    @Override
    @CachePut(key = "#book.id")
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }

    //   @Override
    //now this method will executed only if cache miss, if cache hit, method wont be executed
//    @Cacheable(cacheNames = {"books", "isbns"})
//    public Book getBook(long id) {
//        logger.info("fetching book from db");
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

    @Override
    @Cacheable(key = "#id")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }
    //conditional : cache only books whose id greater than 5
//    @Override
//    @Cacheable(cacheNames = "books", condition = "#id>5 ")
//    public Book getBook(long id) {
//        logger.info("fetching book from db" + id);
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

//    @Override
//    @Cacheable(cacheNames = "books",  unless = "#id==3")
//    public Book getBook(long id) {
//        logger.info("fetching book from db" + id);
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

    @Override
    @CacheEvict(key = "#id", allEntries = true)
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
}
//////////////////////////////////////////////////////////////////////////////////////////////

                                         Redis


What Redis Stands For?

  Remote Dictionary Server.

History of Redis:

 Redis was developed by a developer Salvatore Sanfilippo, who released on May 10, 2009.

What is Redis?
  Redis is an in-memory data structure store, used as a distributed, in-memory key–value database, cache ,message broker.

in-memory : 
   Data is stored in RAM.

Distributed
   Data can be replicated across multiple instances of process(redis).

database:
  The place where we can store data.

Use cases of Redis:

-Distributed Enterprise cache system.
-Message broker - like RabitMQ,Kaffa
-Used as NoSql database.

///////////////////////////////////////////////////////////////////////////////////////////

Redis as NoSql Database:
........................

Data Storage Models:

-File system
-DBMS
-RDBMS- Based Relational Algerba theory proposed by Dr.Codd
IBM invented a language to talk to RDBMS - SQL

-Storing data in the form of tables.
 which is structure which stores data in the row-colum 

 row defins data

 column defines indentifier for data.

 column
 |
 id    username   password 
 1      admin      root  -row

In RDBMS, data is grouped under tables,views- database objects.
Database objects are groued under one object called schema(database).
Many schemas can be groued inside a process -  Database Instance.

RDBMS has been good for lot of use case for more than 4 decades, after 2005,many biz uses
cases required different data models.

RDBMS Drawbacks:

1.Properity Solution
  Like Oracle,IBM,SQL Server - Single vendor
2.Fixed schema objects
   once table is designed, after adding huge amount of data, if you want to add new column /
   delete column.
3.Open source soultions

4.Dynamic raw data.
   i want to store comments ,ratings about the particular product.

Birth of NOSQL:

 -Open source soultions
 -Dynamic schema
***********************************************XXXXXXXXX**********************************
Types of NOSQL Databases:
........................

 column
 |
 id    username   password 
 1      admin      root  -row

id is column
username is column
password is column.
1 value
admin value
root value

Different kind of data models in NoSQL are : 
- Key-Value
- Document 
- Column Family
- Graph 

Key-Value:
...........

 ->It is one of the data structure 
    ->Dictionary
    ->Map

Data Structure :
   Store data using some structure.

eg:
   int id=1
   String userName="admin"
   String password ="root"
 
 Single Dimension:

  User [] users = {new User(),new User()}
  List<User> users= Arrays.asList(new User(),new User())
 Two dimension:
    key,value
  HashMap map = new HashMap();
  map.put("id",1)
  map.put("name","admin") - key-value
 
    
Relational model to Key-Value:
..............................

1.in relational model data is indentified by primary key.


  id - 1 ----- user name - vlaue  pass word -value. - row

2.collection of data is indentied by table name

  users
   id    username   password 
   1      admin      root 
   2      root       super

how to read data
   users.id ---> 
 select id,username,password from users where id=1
.........................................................................................

 objectname:identifier:column

eg:
      
          key         value
           |
     users:1:id         1
     users:1:username  admin
     users:1:password  root

     users:2:id        2
     users:2:username  root
     users:2:password  super

     users:3:id        3
     users:3:username  subu
     users:3:password  foo
     users:3:otp       ""

 read data

     $>users:3:otp
     12345
    
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Document Oriented Data Model:
...............................

Data is stored inside datastore as document.

Document is collection of data.

Document can be any thing.

Types of document

1.structure document
2.unstructure document.

structure document has some structures.

-SGML
-HTML
Data oriented documents
-XML
-JSON
-Properties
-YAML

JSON
{
    "FirstName": "Bob", 
    "Address": "5 Oak St.", 
    "Hobby": "sailing"
}

XML
<contact>
    <firstname>Bob</firstname>
    <lastname>Smith</lastname>
    <phone type="Cell">(123) 555-0178</phone>
    <phone type="Work">(890) 555-0133</phone>
    <address>
      <type>Home</type>
      <street1>123 Back St.</street1>
      <city>Boys</city>
      <state>AR</state>
      <zip>32225</zip>
      <country>US</country>
    </address>
  </contact>

How to store document into database?
 Birth of document oriented

Mongodb
...........................................................................................

Column-Family:
..............

 {
   12345: {
     profile:{}
     orders:{}

   }
     
 }

 invoice:1234:profile   id 1 name xxx address xxx
///////////////////////////////////////////////////////////////////////////////////////////

Graph database:

 collection of inter connected nodes , each node defines its own data.

Neo4j:
............................................................................................

Redis Architecture:
...................

->Redis is written in c language.
->Redis has been distributed to various platforms
->Redis is distributed in two flavours
  -Open Source
     redis.io
  -Commerical
    https://redislabs.com/

->Redis is distributed to BSD,linux operating systems only, no windows distribution.
  -How to use redis on windows
     ->Via VM - inside vm , you can have linux
     ->Via docker easy to use.
     ->Via windows Linux subsystem.


->Redis supports non blocking /Async arch
   Linux provides kernal lib called - epoll



suppose if you are using on linux

 -source code distribution

 -installer - not recommended


Redis storage Model:

-Redis stores data in mememory -RAM , it never stores data in disk.
-Redis is the first fastest INMEMORY data Store.
-Redis stores data in the form of "Key-Value" Pair Model.
-Redis is powered by "Data Structures"

Data Structure Supported by Redis:
..................................
 Dictionary
    key -value

When you define key, you can tell the data type of key.

When you define value, value type must be defined.

Value Types:
............
1.String
2.List
3.Hash
4.Set
5.SortedSet
6.bitMap
7.hyperloglog
8.Geospatial

Value types define, how many values can be stored in a single given key.

eg:
   key              value

   id                1        -Single value /Scallar

   name             Subramanian  -Single value /scallar

   skills           java,redis,microservices  ---- List of values - List  

   address          street:'10thstreet',city:'Coimbatore'  -Hash

   hitcount         1,2,1,2,3,3,4,5,6 -> 1,2,3,4,5,6   -Set - Like List without duplicates

   sequences        34,1,2,5,5,3,2 -> 1,2,3,5,34   -Sorted Set - Like List without duplicates                                                                 + sorting
  
////////////////////////////////////////////////////////////////////////////////////////////

Redis features:

1.for development
 how to store ,reterive, process datas
 datatypes
 commands
 pipelining
 transactions
 pub-sub pattern- message broker
 scripting -lua scripting -- plsql


2.for adminstrations
-how to start server in standalone.
-how to start server in master-replica - scalability - distributed
-how to start server in master-replicat with highavailablity - clusters,sentinals
-security - acl,ssl...
-Monitoring
  -memory manangement
  -client management
  -health managment
-configuration
   -many configurations details
-Persistency.


3.How to extend redis core functionality.
  
Redis allows to add more features apart from core redis distribution.

Redis modules:
  plugable code, can be added to enchance redis

eg:
 can i store json document into redis?
   No
 but is possible via redis modules.

Popular Modules:

1.RedisSearch
2.RedisJson
3.RedisGraph
4.RedisTimeSeries
//////////////////////////////////////////////////////////////////////////////////////////////

Redis components:

1.Redis Server

  Provided by redis.io/redis labs

2.Redis Clients
 Most of the programming languages supports client libs

Java:
-Jedis
-lettuce
-Spring provides spring-data-redis - which runs on either jedis,lettuce

CommandLine clients:
 redis-cli ; cli tool for testing and prototyping , administration...

////////////////////////////////////////////////////////////////////////////////////////////

Lets Program with Redis:
.......................

Setup:
......

1.Using docker.

 docker run -–name redis -p 6379:6379 redis

The default port ; 6379.

Redis where stores data.
 inside database.

Redis process supports by default 16 databases,each database is named by number like 0...15
database[0]>

How to run redis-cli?

docker exec -it redis redis-cli
 
////////////////////////////////////////////////////////////////////////////////////////////

Rediscli is client which communicates redis server via "RedisProtocol"

In RDBMS , Database clients send request, and server returns response.

request could be "Commands" - SQL commands 
 -DDL  - create,grant,revoke\ 
 -DML   - Select,insert,update
 -DCL   - commit,set save point

response would be , rows,or error,no of rows affected...

IN Redis
  Clients will send Commands , server will return response.

Redis offers lot of commands based on datatype,administration,utitlity category.

How to test server is working or not? : health checking.

127.0.0.1:6379> ping
PONG
127.0.0.1:6379> ping "Hello Redis!"
"Hello Redis!"
127.0.0.1:6379>

How to get Server info?

127.0.0.1:6379> INFO
# Server
redis_version:6.0.4
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:d5d470262d47f1a0
redis_mode:standalone
os:Linux 4.19.121-linuxkit x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:1
run_id:84ea3a2dc0e6a9606b54cc39f906803e7d22a027
tcp_port:6379
uptime_in_seconds:368
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:14188345
executable:/data/redis-server
config_file:

# Clients
connected_clients:2
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:887288
used_memory_human:866.49K
used_memory_rss:7561216
used_memory_rss_human:7.21M
used_memory_peak:887288
used_memory_peak_human:866.49K
used_memory_peak_perc:100.00%
used_memory_overhead:836820
used_memory_startup:802848
used_memory_dataset:50468
used_memory_dataset_perc:59.77%
allocator_allocated:1178984
allocator_active:1433600
allocator_resident:3796992
total_system_memory:2085830656
total_system_memory_human:1.94G
used_memory_lua:37888
used_memory_lua_human:37.00K
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.22
allocator_frag_bytes:254616
allocator_rss_ratio:2.65
allocator_rss_bytes:2363392
rss_overhead_ratio:1.99
rss_overhead_bytes:3764224
mem_fragmentation_ratio:8.95
mem_fragmentation_bytes:6716440
mem_not_counted_for_evict:0
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:33972
mem_aof_buffer:0
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1608023497
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:-1
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:0
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0

# Stats
total_connections_received:2
total_commands_processed:7
instantaneous_ops_per_sec:0
total_net_input_bytes:137
total_net_output_bytes:47490
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:3
evicted_keys:0
keyspace_hits:0
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:0
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0

# Replication
role:master
connected_slaves:0
master_replid:7b14ce66bea6d5afd8ceb2942cc144359e218c36
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:0.162191
used_cpu_user:0.153654
used_cpu_sys_children:0.001343
used_cpu_user_children:0.001118

# Modules

# Cluster
cluster_enabled:0

# Keyspace
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////

How to save simple data into redis server?

Command:
SET 
GET

SET key value [EX seconds|PX milliseconds|KEEPTTL] [NX|XX] [GET]

127.0.0.1:6379> SET message "Hello Redis!!"
OK

Here We send key via set command to server, server will execute that command, stores data with
key-value, once success it returns RESPONSE - OK.

GET key

127.0.0.1:6379> GET message
"Hello Redis!!"
/////////////////////////////////////////////////////////////////////////////////////////////

Commands: Keys:
..............

How to read all keys or some of the keys?

 KEYS
 SCAN

1.KEYS pattern

Returns all keys matching pattern.

127.0.0.1:6379> KEYS *
1) "message"

127.0.0.1:6379> KEYS m?ssage
1) "message"

Redis uses glob-style pattern similar to regex pattern.

Keys
-Blocks until complete
   lets say database contains million keys, it blocks database long time
 Recommendation : dont use in production, use it in dev and testing env only.

Scan :
  iterates over cursor
  it also blocks but only iterates over handful  of keys at  the time.
  Returns slot references
  May return 0 or more keys per call.
  Safe for production.



127.0.0.1:6379> scan 0 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 15 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379> scan 14 MATCH * COUNT 4
1) "9"
2) 1) "d1"
   2) "b"
   3) "message"
   4) "e"
127.0.0.1:6379> scan 9 MATCH * COUNT 4
1) "0"
2) 1) "a1"
   2) "e1"
   3) "b1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////
Redis Key Modeling Patterns: Redis community Recommendation:
............................................................

KEY NAME:

Plain keynames
   A    10
   X    20
   name "subramanian"

Redis coding standard:
  objectname:identifier:subidentifier

i want to store order status

  order:1  available
  order:2  outofstock
  order:3  pending
  user:1:status online

127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> get order:2 "outofstock"
OK
127.0.0.1:6379> set user:1:status online
OK
127.0.0.1:6379> set user:2:status online
OK
127.0.0.1:6379> set user:3:status offline

////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////

KEYS REMOVAL: DEL and Unlink
/////////////////////////////


DEL key [key ...]

Removes the specified keys. A key is ignored if it does not exist.

Return value
Integer reply: The number of keys that were removed.

-The DEL Command will remove the key and memory associated with the key.
-This is performed as a blocking opertion.

UnLink:
......
-With UNLINK, key is unlinked , hence the name of the  command and will no longer exists.
-The memory associated with the key value is reclaimed by an asynchronous process,so the UNLINK is a  non-blocking command.


127.0.0.1:6379> DEL a
(integer) 1
127.0.0.1:6379> DEL a a1
(integer) 1
127.0.0.1:6379> DEL b b1
(integer) 2
127.0.0.1:6379> UNLINK  c c1
(integer) 2
127.0.0.1:6379> get c
(nil)
127.0.0.1:6379> get a
(nil)
127.0.0.1:6379>

Note:
 if key does not exit , it returns "nil"

///////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////

However, there are times when you only want to set the value if the key already exists.

EXISTS key [key ...]

EXISTS customer:1000
127.0.0.1:6379> EXISTS customer:2000
(integer) 1
127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379>

it returns 1 for key present , 0 means no key present

Use case :

Why should i use exits command to verify the existing of key.

Operations:
 - new Key - insert
 - update key  -  update.

how to add new key

-SET Command
127.0.0.1:6379> SET customer:9000 jane
OK
127.0.0.1:6379> GET customer:9000
"jane"

what if i want to update customer name of customer:9000
SET Command

127.0.0.1:6379> SET customer:9000 "jane james"
OK
127.0.0.1:6379> GET customer:9000
"jane james"
127.0.0.1:6379>



127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379> SET customer:9000 jane
OK

You could first check with the exist command to see if the key is present before using SET.

But having two operations-- the exists followed by a set--means two round trips Redis and possible inconsistencies between the operations.

NX -  for create
XX -  for update.

127.0.0.1:6379> SET customer:333 john NX
OK
127.0.0.1:6379> SET customer:333 john NX
(nil)
127.0.0.1:6379> SET customer:444 Karthik XX
(nil)
127.0.0.1:6379> SET customer:444 Karthik NX
OK
127.0.0.1:6379> SET customer:444 Karthik.K XX
OK
127.0.0.1:6379> GET customer:444
"Karthik.K"
127.0.0.1:6379>

/////////////////////////////////////////////////////////////////////////////////////////////

Timers : Automatic Key Eviction:
.................................
timeout in sec- ex
timeout in msc -px
TTL key - to verify , how much time is there 
	
27.0.0.1:6379> SET seat-hold Row:A:Seat:4 EX 5000
OK
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> TTL seat-hold
(integer) 4957
127.0.0.1:6379> TTL seat-hold
(integer) 4952
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> TTL user:password
(integer) -2
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379> exists user:password
(integer) 0
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> exists user:password
(integer) 1
127.0.0.1:6379> get user:password
"something"
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////

                                             Data types
1.String:
 -store alphabets
 -store numbers
 -store binary.
    -image,spreadsheets,html fragments

no int,float datatype.

There is a limit of 512 megabytes for any string value

JPEGs, Excel spreadsheets, HTML fragments, as well as
plain old regular text and numbers are permissible.

Internally, Redis stores encoding of the value, stores a knowledge of whether it is a text, number, or binary.
 1 - integer
 "a" - string
 binary - bytes-raw

How to know the type of key?

TYPE key

127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string

Since string is Super Type, 10 also stored as string but it is numeric value.

Can i do some computation on numerical value.
Yes!

in order to know the internal type of string

OBJECT subcommand key

The OBJECT command allows to inspect the internals of Redis Objects associated with keys

OBJECT ENCODING <key> returns the kind of internal representation used in order to store the value associated with a key.

127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string
127.0.0.1:6379> INCR a
(integer) 11
127.0.0.1:6379> INCR b
(integer) 11
127.0.0.1:6379> OBJECT ENCODING a
"int"
127.0.0.1:6379> OBJECT ENCODING b
"int"
127.0.0.1:6379> OBJECT ENCODING name
"embstr"
127.0.0.1:6379> OBJECT ENCODING c
"embstr"
127.0.0.1:6379> INCR name
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCR c
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCRBYFLOAT c
(error) ERR wrong number of arguments for 'incrbyfloat' command
127.0.0.1:6379> INCRBYFLOAT c 1
"11.5"
127.0.0.1:6379> INCRBYFLOAT c 1
"12.5"
127.0.0.1:6379> INCRBY a 10
(integer) 21
127.0.0.1:6379> INCRBY a 10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> DECR a
(integer) 30
127.0.0.1:6379> DECRby a 5
(integer) 25
127.0.0.1:6379> DECRby a 5
(integer) 20
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

String operations:

-string length
-stringrange
-append

127.0.0.1:6379> STRLEN name
(integer) 11
127.0.0.1:6379> set name "Subramanian"
OK
127.0.0.1:6379> GETRANGE name 0 4
"Subra"
127.0.0.1:6379>

127.0.0.1:6379> APPEND name "Murugan"
(integer) 18
127.0.0.1:6379> get name
"SubramanianMurugan"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

Streo type commands:

 -Commands looks like but which gives semantic meaning and simple use to

MSET key value [key value ...]
////////////////////////////////////////////////////////////////////////////////////////////

Bit Maps:
........

Collection of bits which forms a structure called bit map.

BitMaps are  a data type used within Redis and represents a long list of bits that contain 0 by default and we can use SETBIT Command to flip to 1 or 0


Key                    Value                               type
	
a_bitmap     0 0 0  0 0 0 0 0 0 0 0 0 0 0                  binary string


bitmap can store up to 2pow 32 bits,about 4 billion items

Use case: login use case

SETBIT logins:2017:04 6 1

here login:2017:04 is key
6 is offset , typically userid as offset
1 is active bit

SETBIT logins:2017:04 6 1

27.0.0.1:6379> SET login:today 7 1
(error) ERR syntax error
127.0.0.1:6379> SETBIT login:today 7 1
(integer) 0
127.0.0.1:6379> SETBIT login:today 7 0
(integer) 1
127.0.0.1:6379> GET login:today
"\x00"
127.0.0.1:6379> Type login:today
string
127.0.0.1:6379> object encoding login:today
"raw"
127.0.0.1:6379>

types:
 int -numbers
 embstr -embededstring
 raw - binary- bits
/////////////////////////////////////////////**************//////////////////////////////////

Hash:
.....

String stores single/scalar value only

 SET a 10

Hash Stores key-value pair values into one single key

    player:1
        name:xxx
        score:12
        status:available

H-SET =>HashSet

HSET key field value [field value ...]

127.0.0.1:6379> HSET player:1 name Subramanian score 80 status alive
(integer) 3
127.0.0.1:6379> HSET houseId:5150 numBedrooms 3 sqfeet 2700 hvac "forced air"
(integer) 3
1

internal represention would be like below
  
player:1 
       {
         name:'subramanina',
         score:80,
         status:'alive'
       }


houseID: 5150
	numBedrooms: 3
	squareFeet: 2700
	hvac: forced air


Commands:

HSET - to add field and values
HGETALL - to read all hash values
HGET  - TO get a particular key value
HSET - to update existing field or add new field value
HDEL - to delete a field value from existing hash
HINCRBY - to increment a field value

Reading Keys and key
......................
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Subramanian"
3) "score"
4) "80"
5) "status"
6) "alive"
127.0.0.1:6379> HGET player:1 name
"Subramanian"
127.0.0.1:6379> HGET player:1 status
"alive"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////
How to maniupulate a field in hashset?

HINCRBY key field increment
HINCRBYFLOAT key field increment

127.0.0.1:6379> HINCRBY player:1  score 5
(integer) 85
127.0.0.1:6379> HINCRBY player:1  score 5
........................................................

How to update existing fields in hash set?

You can update single field or multiple fields?

127.0.0.1:6379> HSET player:1 name "Ram Kumar"
(integer) 0
127.0.0.1:6379> HGET player:1 name
"Ram Kumar"
127.0.0.1:6379> HSET player:1 name "Ram Kumar" score 10
(integer) 0
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
127.0.0.1:6379>
.......................................................................................
How to add new field on existing hash?

127.0.0.1:6379> HSET player:1  level 5
(integer) 1
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
7) "level"
8) "5"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////

How to delete field/s from hash?

HDEL key field [field ...]

27.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "status"
6) "alive"
7) "level"
8) "5"
127.0.0.1:6379> HDEL player:1 status
(integer) 1
127.0.0.1:6379> HGETALL player:1
1) "name"
2) "Ram Kumar"
3) "score"
4) "10"
5) "level"
6) "5"
127.0.0.1:6379>

///////////////////////////////////////////////////////////////////////////////////////////

How to verify a particular field present or not on existing hash?

HEXISTS key field

127.0.0.1:6379> HEXISTS player:1 status
(integer) 0
127.0.0.1:6379> HEXISTS player:1 level
(integer) 1
127.0.0.1:6379>
...........................................................................................
How to extract only keys and values from Hash?

Keys Only:

127.0.0.1:6379> HKEYS player:1
1) "name"
2) "score"
3) "level"

Values Only:
127.0.0.1:6379> HVALS player:1
1) "Ram Kumar"
2) "10"
3) "5
//////////////////////////////////////////////////////////////////////////////////////////////
                                     List
                                   .........

1.List is ordered collection of strings.
2.List maintains order based index, which starts 0th index.
3.Lists are dynamic array,you can add,delete items dynamically, as you add or delete,
  the size of list automatically expanded or shrinked.
4.Lists are implemented as "Doubly Linked List" : Linked List
5.You can add element at any position :  head / tail - left /right.
6.You can create other usefull data structures like "Queues/ Stacks,PQueues"
7.Duplicates are allowed.

List Operations:

1.Add Elements at Head

LPUSH key element [element ...]

127.0.0.1:6379> LPUSH  names a b c d e
(integer) 5
127.0.0.1:6379>

............................................................

2.Get No of elemenents In the List

LLEN key

127.0.0.1:6379> LLEN names
(integer) 5
...................................................................
3.How read elements from left most?

127.0.0.1:6379> LPUSH  names a b c d e
(integer) 5

LPush adds element left side

Internal storage would be for LPUSH 
 e,d,c,a,b

127.0.0.1:6379> LRANGE names 0 5
1) "e"
2) "d"
3) "c"
4) "b"
5) "a"
127.0.0.1:6379> LRANGE names 2 5
1) "c"
2) "b"
3) "a"
127.0.0.1:6379> LRANGE names 3 5
1) "b"
2) "a"
...........................................................................................
3.1. How to read single element based on index?

LINDEX key index

 - 0 means first index element
 - -1 last tail element
 - outofindex - nil

127.0.0.1:6379> LRANGE names 0 7
1) "c"
2) "redis-cli"
3) "b"
4) "a"

Get the first element:

127.0.0.1:6379> LINDEX names 0
"c"

127.0.0.1:6379> LINDEX names 1
"redis-cli"
127.0.0.1:6379> LINDEX names -1
"a"
127.0.0.1:6379> LINDEX names -2
"b"
127.0.0.1:6379> LINDEX names 90
(nil)
127.0.0.1:6379>

/////////////////////////////////////////////////////////////////////////////////////////////

How to update/replace old node value into new node value?

Before update:
127.0.0.1:6379> LRANGE names 0 5
1) "e"
2) "d"
3) "c"
4) "b"
5) "a"

After update:
127.0.0.1:6379> LSET  names 0 "foo"
OK
127.0.0.1:6379> LRANGE names 0 5
1) "foo"
2) "d"
3) "c"
4) "b"
5) "a"
////////////////////////////////////////////////////////////////////////////////////////////

How to add element in the middle of the List?

LINSERT key BEFORE|AFTER pivot element


127.0.0.1:6379> LRANGE names 0 5
1) "foo"
2) "d"
3) "c"
4) "b"
5) "a"
127.0.0.1:6379> LINSERT names BEFORE "c" "redis"
(integer) 6
127.0.0.1:6379> LRANGE names 0 6
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "b"
6) "a"
127.0.0.1:6379> LINSERT names AFTER "c" "redis-cli"
(integer) 7
127.0.0.1:6379> LRANGE names 0 7
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "redis-cli"
6) "b"
7) "a"
///////////////////////////////////////////////////////////////////////////////////////////
How to remove element from the Left side?

LPOP key

Before Remove:
..............

127.0.0.1:6379> LRANGE names 0 7
1) "foo"
2) "d"
3) "redis"
4) "c"
5) "redis-cli"
6) "b"
7) "a"
127.0.0.1:6379> LPOP names
"foo"
127.0.0.1:6379> LPOP names
"d"
127.0.0.1:6379> LPOP names
"redis"

After Remove:
.............

127.0.0.1:6379> LRANGE names 0 7
1) "c"
2) "redis-cli"
3) "b"
4) "a"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

RPUSH : Pushing elements towards right
......................................

RPUSH key element [element ...]

Add elements:

127.0.0.1:6379> RPUSH  counters 1 2 3 4 5 6 7 8 9 10
(integer) 10

127.0.0.1:6379> LRANGE counters 0 9
 1) "1"
 2) "2"
 3) "3"
 4) "4"
 5) "5"
 6) "6"
 7) "7"
 8) "8"
 9) "9"
10) "10"

127.0.0.1:6379> LRANGE counters 0 9
 1) "1"
 2) "2"
 3) "3"
 4) "4"
 5) "5"
 6) "6"
 7) "7"
 8) "8"
 9) "9"
10) "10"
127.0.0.1:6379> RPOP counters
"10"
127.0.0.1:6379> LPOP counters
"1"
127.0.0.1:6379>
/////////////////////////////////////////////////////////////////////////////////////////

Think how to implement stacks and queues using list?
.....................................................

STACK - LPUSH ,LPOP
Queue - RPUSH, LPOP
.........................................................................................

                                      SET
............................................................................................ 

Sets:
 -Unordered collection without duplicate values.
 -Provides mathmetical set operations - union,intersection,difference.

How to create set / how to add elements set?

SADD key member [member ...]

127.0.0.1:6379> SADD hitcounters 1 1 2 3 3 4 5 6 7 8 8
(integer) 8

How to get all keys and values?

SSCAN key cursor [MATCH pattern] [COUNT count]

127.0.0.1:6379> SSCAN hitcounters 0 MATCH *
1) "0"
2) 1) "1"
   2) "2"
   3) "3"
   4) "4"
   5) "5"
   6) "6"
   7) "7"
   8) "8"
127.0.0.1:6379>

////////////////////////////////////////////////////////////////////////////////////////

Cardinality: SCARD

SCARD key

-Returns the set cardinality (number of elements) of the set stored at key.

127.0.0.1:6379> SCARD hitcounters
(integer) 8

////////////////////////////////////////////////////////////////////////////////////////////

Differences:SDIFF

SDIFF key [key ...]

-Returns the members of the set resulting from the difference between the first set and all the successive sets.

127.0.0.1:6379> SADD key1 a b c d
(integer) 4
127.0.0.1:6379> SADD key2 c
(integer) 1
127.0.0.1:6379> SADD key3 a c e
(integer) 3
127.0.0.1:6379> SDIFF key1 key2 key3
1) "b"
2) "d"
////////////////////////////////////////////////////////////////////////////////////////////

Union : eleminate common elements

127.0.0.1:6379> sadd key1  a b c d e
(integer) 5
127.0.0.1:6379> sadd key2 c
(integer) 1
127.0.0.1:6379> sadd key3 f g c
(integer) 3
127.0.0.1:6379> sunion key1 key2 key3
1) "f"
2) "c"
3) "b"
4) "a"
5) "d"
6) "e"
7) "g"
127.0.0.1:6379>
///////////////////////////////////////////////////////////////////////////////////////////////
Intersection: Common element

SINTER key [key ...]

Returns the members of the set resulting from the intersection of all the given sets.

127.0.0.1:6379> SADD key1 a b c d
(integer) 4
127.0.0.1:6379> SADD key2 c
(integer) 1
127.0.0.1:6379> SADD key3 a c e

127.0.0.1:6379> SINTER key1 key2 key3
1) "c"

//////////////////////////////////////////////////////////////////////////////////////////

How to get members of a given set?

SMEMBERS key


127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
127.0.0.1:6379> SMEMBERS key2
1) "c"
127.0.0.1:6379> SMEMBERS key3
1) "c"
2) "e"
3) "a"
127.0.0.1:6379>
///////////////////////////////////////////////////////////////////////////////////////////

To test whether an element is member of a given set?

SISMEMBER key member
 
1-means memeber
0-means not a member

127.0.0.1:6379> SISMEMBER key1 a
(integer) 1
127.0.0.1:6379> SISMEMBER key1 ab
(integer) 0
127.0.0.1:6379>

////////////////////////////////////////////////////////////////////////////////////////////

How to remove element from Set?

Remove from first index

SPOP key [count]

127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
127.0.0.1:6379> SPOP key1
"a"
127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
127.0.0.1:6379> SPOP key1  2
1) "c"
2) "d"
127.0.0.1:6379> SMEMBERS key1
1) "b"
127.0.0.1:6379>

Remove based on element

SREM key member [member ...]

127.0.0.1:6379> SMEMBERS key1
1) "c"
2) "d"
3) "b"
4) "a"
5) "e"
127.0.0.1:6379> SREM key1 c
(integer) 1
127.0.0.1:6379> SMEMBERS key1
1) "d"
2) "b"
3) "a"
4) "e"
////////////////////////////////////////////////////////////////////////////////////////
How to select random values from the set?

SRANDMEMBER key [count]

127.0.0.1:6379> SRANDMEMBER key1
"d"
127.0.0.1:6379> SRANDMEMBER key1
"d"
127.0.0.1:6379> SRANDMEMBER key1
"b"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "e"
2) "a"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "d"
2) "b"
127.0.0.1:6379> SRANDMEMBER key1 2
1) "d"
2) "b"
//////////////////////////////////////////////////////////////////////////////////////////////
                                   
                                      SORTED SET
///////////////////////////////////////////////////////////////////////////////////////////////

 -Sorted set is similar to set with sorting feature. asc or dec order - based on numbers/charcaters

127.0.0.1:6379> ZADD myset 1 a
(integer) 1
127.0.0.1:6379> ZADD myset 1 a
(integer) 0
127.0.0.1:63
79> ZADD myset 1 b
(integer) 1
127.0.0.1:6379> ZADD myset 2 c 3 d
(integer) 2
127.0.0.1:6379> ZRANGE myset 0 -1 WITHSCORES
1) "a"
2) "1"
3) "b"
4) "1"
5) "c"
6) "2"
7) "d"
8) "3"
127.0.0.1:6379> ZRANGE myset 0 -1
1) "a"
2) "b"
3) "c"
4) "d"
127.0.0.1:6379> ZADD myset 0 e
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
127.0.0.1:6379> ZADD myset 10 foo
(integer) 1
127.0.0.1:6379> ZADD myset 5 bar
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
6) "bar"
7) "foo"
127.0.0.1:6379> ZADD myset 9 foobar
(integer) 1
127.0.0.1:6379> ZRANGE myset 0 -1
1) "e"
2) "a"
3) "b"
4) "c"
5) "d"
6) "bar"
7) "foobar"
8) "foo"
127.0.0.1:6379>

Note: 
 sorting happens based "score" values, incase scores are same, then redis sorts according to
 ordered lexicographically of values.

Note: Most of the Sort apis available inside Sorted Set + Some advanced apis also , which is based on scores and ranks.
/////////////////////////////////////////////////////////////////////////////////////////////
				Transactions
//////////////////////////////////////////////////////////////////////////////////////////////

  Grouping set of commands as a single unit of execution called transaction.

IN rdbms
 COMMIT  - ALL Success
 rollback - revert

Sequences of commands you can send

 MULTI
 EXEC
 DISCARD

Transaction will be enabled with more than one connections or single connection.


Commands work flow in redis:

General workflow

 SET a 10--------sends--to---redisserver-----|receive command --Execute---Return  status

 127.0.0.1:6379> SET counter 0
OK -Response

Transaction work flow:
.......................

 In transactions commands wont be executed immediately, rather than , commands will be 
 Queued.... until there signal for success.

MULTI -  starts transaction
 COMMAND 1
 COMMAND 2
 COMMAND 3
--QUEUED
EXEC- EXECUTE transactions

127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> GET counter
QUEUED
127.0.0.1:6379> EXEC
1) (integer) 1
2) "1"
127.0.0.1:6379>

How to discard transactions? - Rollback:

127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> INCRBY counter 10
QUEUED
127.0.0.1:6379> DISCARD
OK
127.0.0.1:6379> GET counter
"1"
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////                              Redis and Java
.............................................................................................

Java provides two major libs

1.jedis
2.Lettuce

Java and Reactive Programming : RXJAVA,Reactor


Lettuce:

It is advanced redis wrapper.

-Reactive,functional style wrapper.

Redis can be connected in non blocking and reactive.

Where lettuce helps to connect and query redis in async and nonblocking way.

if you are going to use jedis / lettuce, in java program.

///////////////////////////////////////////////////////////////////////////////////////////

Create simple maven project

    <dependency>
        <groupId>redis.clients</groupId>
        <artifactId>jedis</artifactId>
        <version>2.10.2</version>
        <type>jar</type>
        <scope>compile</scope>
    </dependency>


HelloRedis.java
package com.redis.hello;

import redis.clients.jedis.Jedis;

public class HelloRedis {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost", 6379);
        System.out.println(jedis.ping());
        System.out.println(jedis.ping("Hello Redis!!!"));

    }
}

////////////////////////////////////////////////////////////////////////////////////////////

How to use Strings:

27.0.0.1:6379> SET article:12345:headlines "Redis is the fastest Datastore"
OK
127.0.0.1:6379> SET article:60056:headlines "Redis is best for indexing"
OK
127.0.0.1:6379> SET article:10001:headlines "Redis is best for caching"
OK
127.0.0.1:6379> SET article:12345:headlines "Redis is the fastest Datastore"
OK

package com.redis.strings;

import redis.clients.jedis.Jedis;

import java.util.List;

class VotingSystem {
    private Jedis jedis;

    VotingSystem(Jedis jedis) {
        this.jedis = jedis;
    }

    public void upVote(int id) {
        String key = "article:" + id + ":votes";
        jedis.incr(key);

    }

    public void downVote(int id) { // 1
        String key = "article:" + id + ":votes"; // 2
        jedis.decr(key); // 3
    }

    public void showResults(int id) {
        String headlineKey = "article:" + id + ":headlines";
        String voteKey = "article:" + id + ":votes";
        List<String> keys = jedis.mget(headlineKey, voteKey);
        keys.forEach(System.out::println);
    }
}

public class RedisStrings {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost");
        jedis.set("name", "subramanian");
        System.out.println(jedis.get("name"));
        System.out.println(jedis.get("counter"));
        VotingSystem votingSystem = new VotingSystem(jedis);
        votingSystem.upVote(12345); // article:12345 has 1 vote
        votingSystem.upVote(12345); // article:12345 has 2 votes
        votingSystem.upVote(12345); // article:12345 has 3 votes
        votingSystem.upVote(10001); // article:10001 has 1 vote
        votingSystem.upVote(10001); // article:10001 has 2 votes
       // votingSystem.downVote(10001); // article:10001 has 1 vote
        votingSystem.upVote(60056); // article:60056 has 1 vote
        votingSystem.showResults(12345);
        votingSystem.showResults(10001);
        votingSystem.showResults(60056);

    }
}
//////////////////////////////////////////////////////////////////////////////////////////////

How to dealwith List?

package com.redis.list;

import redis.clients.jedis.Jedis;

public class ListRedis {
    public static void main(String[] args) {
        Jedis jedis = new Jedis("localhost");
        jedis.lpush("mylist", "1");
        jedis.lpush("mylist", "2");
        jedis.lpush("mylist", "3");
        jedis.lpush("mylist", "4");
        jedis.lpush("mylist", "5");
        jedis.lrange("mylist", 0, 10).forEach(System.out::println);
    }
}
//////////////////////////////////////////////////////////////////////////////////////////////

                               Spring Boot + Redis Integration
/////////////////////////////////////////////////////////////////////////////////////////////

Spring Boot Provides an abstraction for redis

    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>

Spring Boot provides a high level abstraction apis to talk to redis, in order to talk to Redis
we need drivers -  Jedis,Lettuce.


                                    Spring Boot Redis
					   |
			---------------------------------------------
                        |                                           |
                     Jedis                                      Lettuce



Connecting Redis:

org.springframework.data.redis.connection package contains redis related api.


api:

RedisConnection:

-Provides the core building block for redis communication.
-It handles the communication with the redis back end.
-It also automatically translates the underlying connections exections to Spring consistentent DAO  Exception
-RedisConnection uses tcp channel to send and recevice data.

How to create RedisConnection?

  RedisConnection is interface,its implementations are provided by implemenation classes.

Implementation classes provided by low level java libs 
   -jedis, lettuce.


Spring comunnicates jedis/lettuce to get low level communcation.

Spring abstracts even getting connection information from the libs..

				RedisConnection
					|
			---------------------------------------------- RedisConnectionFactory
                       JedisConnection                LettuceConnection


RedisConnectionFactory:

 -It is factory class/bean used to create Redis active connections.

RedisConnectionFactory internally uses JeddisConnectionFactory or LettuceConnectionFactory
...........................................................................................


How to create ConnectionFactory/How to configure Connection factory:

Through @Configuration and @Bean annotation.

package com.tiaa.redis;

import lombok.extern.java.Log;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisStandaloneConfiguration;
import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;
import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory;

@Configuration
@Log
public class AppConfig {
    //connections
    @Bean
    public LettuceConnectionFactory lettuceConnectionFactory() {
        RedisStandaloneConfiguration configuration = new RedisStandaloneConfiguration();
        configuration.setHostName("localhost");
        configuration.setPort(6379);
        log.info("connection factory is initalized : LettuceConnectionFactory ");
        return new LettuceConnectionFactory(configuration);
    }

    //jedis configuration
//    @Bean
//    public JedisConnectionFactory jedisConnectionFactory() {
//        RedisStandaloneConfiguration configuration = new RedisStandaloneConfiguration();
//        configuration.setHostName("localhost");
//        configuration.setPort(6379);
//        log.info("connection factory is initalized : JedisConnectionFactory ");
//
//        return new JedisConnectionFactory(configuration);
//    }
}
////////////////////////////////////////////////////////////////////////////////////////////

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

RedisTemplate:


RedisTemplate looks like other templating arch in spring.

In fact, the Templates are high level abstraction for application level communication.

eg:jdbcTemplate,jpaTemplate,restTemplate.......


RedisTemplate:
............
-The template offers a high-level abstraction for redis interaction.
 Where redis connection offers low level methods that accept and return binary values-byte arrays.

Seralization and Deseralization:

-Template takes cares of seralization,deseralization ,and connection managment.
-template sends commands  to redis server looks like redis command list.

RedisTemplate offers Operational Views:

RedisTemplate offers Operational Views:

-String Operations.

 OperationalView Api

 template.ValueOperations ----Template<Key,Value>
 
SetOperations
ZsetOperations
GeoOperations
ListOperations
SetOperations
//////////////////////////////////////////////////////////////////////////////////////////

How to use apis?

  @Autowired
  private StringRedisTemplate redisTemplate

  redisTemplate.opsForList().leftPush(userId, url.toExternalForm());

////////////////////////////////////////////////////////////////////////////////////////////

You can add configuration properties via application.yaml /properties

spring.redis.host
//////////////////////////////////////////////////////////////////////////////////////////

CURD App using Redis:

pom.xml
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-redis</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>

		<dependency>
			<groupId>org.projectlombok</groupId>
			<artifactId>lombok</artifactId>
		</dependency>
		<dependency>
			<groupId>redis.clients</groupId>
			<artifactId>jedis</artifactId>
			<version>3.3.0</version>
		</dependency>

////////////////////////////////////////////////////////////////////////////////////////////

RedisConnectionFactory Configuration:

@Configuration
public class RedisConfig {

    @Bean
    public JedisConnectionFactory jedisConnectionFactory() {
        RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration();
        redisStandaloneConfiguration.setHostName("127.0.0.1");
        redisStandaloneConfiguration.setPort(6379);
        //redisStandaloneConfiguration.setPassword("password");

        JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(redisStandaloneConfiguration);
        return  jedisConnectionFactory;
    }

    @Bean
    public RedisTemplate<String, Object> redisTemplate() {
        RedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();
        redisTemplate.setConnectionFactory(jedisConnectionFactory());
        redisTemplate.setKeySerializer(new StringRedisSerializer());
        redisTemplate.setHashKeySerializer(new StringRedisSerializer());
        redisTemplate.setHashKeySerializer(new JdkSerializationRedisSerializer());
        redisTemplate.setValueSerializer(new JdkSerializationRedisSerializer());
        redisTemplate.setEnableTransactionSupport(true);
        redisTemplate.afterPropertiesSet();
        return redisTemplate;
    }
}
////////////////////////////////////////////////////////////////////////////////////////////

Enity:
 It must implement Serializable interface
.....................................................................................

import lombok.Data;
import lombok.Getter;
import lombok.Setter;

import java.io.Serializable;

public class User implements Serializable {

    private Long id;
    private String firstName;

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getFirstName() {
        return firstName;
    }

    public void setFirstName(String firstName) {
        this.firstName = firstName;
    }

    public String getLastName() {
        return lastName;
    }

    public void setLastName(String lastName) {
        this.lastName = lastName;
    }

    public String getEmailId() {
        return emailId;
    }

    public void setEmailId(String emailId) {
        this.emailId = emailId;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    private String lastName;
    private String emailId;
    private int age;

}

//////////////////////////////////////////////////////////////////////////////////

DAO class:
..........

public interface UserDao {
    boolean saveUser(User user);

    List<User> fetchAllUser();

    User fetchUserById(Long id);

    boolean deleteUser(Long id);

    boolean updateUser(Long id, User user);
}
import com.dailycodebuffer.model.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public class UserDaoImpl implements UserDao {

    @Autowired
    private RedisTemplate redisTemplate;

    private static final String KEY = "USER";

    @Override
    public boolean saveUser(User user) {
        try {
            redisTemplate.opsForHash().put(KEY, user.getId().toString(), user);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    @Override
    public List<User> fetchAllUser() {
        List<User> users;
        users = redisTemplate.opsForHash().values(KEY);
        return  users;
    }

    @Override
    public User fetchUserById(Long id) {
        User user;
        user = (User) redisTemplate.opsForHash().get(KEY,id.toString());
        return user;
    }

    @Override
    public boolean deleteUser(Long id) {
        try {
            redisTemplate.opsForHash().delete(KEY,id.toString());
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    @Override
    public boolean updateUser(Long id, User user) {
        try {
            redisTemplate.opsForHash().put(KEY, id, user);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
}

////////////////////////////////////////////////////////////////////////////////

Service
import com.dailycodebuffer.model.User;

import java.util.List;

public interface UserService {

    boolean saveUser(User user);

    List<User> fetchAllUser();

    User fetchUserById(Long id);

    boolean deleteUser(Long id);

    boolean updateUser(Long id, User user);
}
Service
public class UserServiceImpl implements UserService {

    @Autowired
    private UserDao userDao;

    @Override
    public boolean saveUser(User user) {
        return userDao.saveUser(user);
    }

    @Override
    public List<User> fetchAllUser() {
        return userDao.fetchAllUser();
    }

    @Override
    public User fetchUserById(Long id) {
        return userDao.fetchUserById(id);
    }

    @Override
    public boolean deleteUser(Long id) {
        return userDao.deleteUser(id);
    }

    @Override
    public boolean updateUser(Long id, User user) {
        return userDao.updateUser(id,user);
    }
}
/////////////////////////////////////
API : Controllr

import com.dailycodebuffer.model.User;
import com.dailycodebuffer.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.List;

@RestController
public class UserController {

    @Autowired
    private UserService userService;

    @PostMapping("/user")
    public ResponseEntity<String> saveUser(@RequestBody User user) {
        boolean result = userService.saveUser(user);
        if(result)
            return ResponseEntity.ok("User Created Successfully!!");
        else
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();
    }

    @GetMapping("/user")
    public ResponseEntity<List<User>> fetchAllUser() {
        List<User> users;
        users = userService.fetchAllUser();
        return ResponseEntity.ok(users);
    }

    @GetMapping("/user/{id}")
    public ResponseEntity<User> fetchUserById(@PathVariable("id") Long id) {
        User user;
        user = userService.fetchUserById(id);
        return ResponseEntity.ok(user);
    }

    @DeleteMapping("/user/{id}")
    public ResponseEntity<String> deleteUser(@PathVariable("id") Long id) {
        boolean result = userService.deleteUser(id);
        if(result)
            return ResponseEntity.ok("User deleted Successfully!!");
        else
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();
    }

    @PutMapping("/user/{id}")
    public ResponseEntity<String> updateUser(@PathVariable("id") Long id, @RequestBody User user) {
        boolean result = userService.updateUser(id,user);
        if(result)
            return ResponseEntity.ok("User Updated Successfully!!");
        else
            return ResponseEntity.status(HttpStatus.BAD_REQUEST).build();
    }
}
//////////////////////////////////////////////////////////////////////////////////////////////

How to Use Redis as Provider?
.............................

       <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-cache</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>com.h2database</groupId>
            <artifactId>h2</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>

///////////////////////////////////////////////////////////////////////////////////////////////

Redis and Cache Configuration:

1.Via code - @Configuration
2.Via PropertySource -application.properties/yaml

# Redis Config

spring.cache.type=redis

spring.cache.redis.cache-null-values=false

spring.cache.use-key-prefix=true

spring.cache.key=books

spring.cache.time-to-live=60000

spring.redis.host=localhost

spring.redis.timeout=10000

spring.redis.port=6379

server.port=8081
/////////////////////////////////////////////////////////////////////////////////////////////

Entity should implement serializable
.....................................

@Entity
public class Book implements  Serializable {
    private static final long serialVersionUID = 1307525040224585678L;
    @Id
    @GeneratedValue
    private long id;
    private String name;
    private String category;
    private String author;
    private String publisher;
    private String edition;

    public long getId() {
        return id;
    }

    public void setId(long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getCategory() {
        return category;
    }

    public void setCategory(String category) {
        this.category = category;
    }

    public String getAuthor() {
        return author;
    }

    public void setAuthor(String author) {
        this.author = author;
    }

    public String getPublisher() {
        return publisher;
    }

    public void setPublisher(String publisher) {
        this.publisher = publisher;
    }

    public String getEdition() {
        return edition;
    }

    public void setEdition(String edition) {
        this.edition = edition;
    }

    @Override
    public String toString() {
        return "Book{" +
                "id=" + id +
                ", name='" + name + '\'' +
                ", category='" + category + '\'' +
                ", author='" + author + '\'' +
                ", publisher='" + publisher + '\'' +
                ", edition='" + edition + '\'' +
                '}';
    }
}
/////////////////////////////&&&&&&&&&&&&&&&&&&&&&&&///////////////////////////////////////

Advanced Topics:
...............

0.How to Start server
  -with configuration
 -redis.conf

1.Persistance
2.Replication : Scalability - Master/Slave Arch.
3.High Availablity And Data Distribution across nodes
   -Partiation
   -Cluster
   -Sentinal
4.Security
   -Client side 
   -ACL - Authentication
   -TSL
5.Monitoring tools


1.Persistance:
 -Save redis inmemory data into disk , in the disk file - dump.rdb or dump.aof

save 900 1
save 300 10
save 60 10000

When to take backup.
 
///////////////////////////////////////////////////////////////////////////////////////////

Replication:

->Scalability
->Master-slave arch
->write operations into masters
->read operations from replicas/slaves
->replication is async

Here demo , i am going to use docker-compose; because , we need to run multiple redis-severs
we need to communicates.

->docker networker bridge

IS There any GUI tool for redis-cli - redis-labs -dashbord, redis-commandar-node.js based tool.


docker-compose.yml
version: '3'
services:
  master:
    container_name: master
    image: redis
    ports:
      - 6379:6379
  slave-1:
    container_name: slave-1
    image: redis
    ports:
      - 16379:6379
    volumes:
      - ./conf:/usr/local/etc/redis/
    command: redis-server /usr/local/etc/redis/redis.conf
  slave-2:
    container_name: slave-2
    image: redis
    ports:
      - 26379:6379
    volumes:
      - ./conf:/usr/local/etc/redis/
    command: redis-server /usr/local/etc/redis/redis.conf    
  redis-commander:
    container_name: redis-commander
    hostname: redis-commander
    image: rediscommander/redis-commander:latest
    restart: always
    environment:
    - REDIS_HOSTS=master:master,slave-1:slave-1,slave-2:slave-2
    ports:
    - 8081:8081

>docker-compose up


Spring Boot - master-slave communication:

application.yaml
redis:
  master:
    host: localhost
    port: 6379
  slaves:
    - host: localhost
      port: 16379
    - host: localhost
      port: 26379


Configuration:
package com.vinsguru.redismasterslave.config;


import io.lettuce.core.ReadFrom;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.connection.RedisStaticMasterReplicaConfiguration;
import org.springframework.data.redis.connection.lettuce.LettuceClientConfiguration;
import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory;

import java.util.List;

@Configuration
@ConfigurationProperties(prefix = "redis")
public class RedisConfiguration {

    private RedisInstance master;
    private List<RedisInstance> slaves;

    RedisInstance getMaster() {
        return master;
    }

    void setMaster(RedisInstance master) {
        this.master = master;
    }

    List<RedisInstance> getSlaves() {
        return slaves;
    }

    void setSlaves(List<RedisInstance> slaves) {
        this.slaves = slaves;
    }

    @Bean
    public LettuceConnectionFactory redisConnectionFactory() {
        LettuceClientConfiguration clientConfig = LettuceClientConfiguration.builder()
                .readFrom(ReadFrom.REPLICA_PREFERRED)
                .build();
        RedisStaticMasterReplicaConfiguration staticMasterReplicaConfiguration = new RedisStaticMasterReplicaConfiguration(this.getMaster().getHost(), this.getMaster().getPort());
        this.getSlaves().forEach(slave -> staticMasterReplicaConfiguration.addNode(slave.getHost(), slave.getPort()));
        return new LettuceConnectionFactory(staticMasterReplicaConfiguration, clientConfig);
    }

    private static class RedisInstance {

        private String host;
        private int port;

        String getHost() {
            return host;
        }

        void setHost(String host) {
            this.host = host;
        }

        int getPort() {
            return port;
        }

        void setPort(int port) {
            this.port = port;
        }
    }

}
///////////////////////////////////////////////////////////////////////////////////////////

Controller
package com.vinsguru.redismasterslave.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RestController;

import java.util.Set;

@RestController
public class RedisController {

    private static final String KEY = "dummy";

    @Autowired
    private StringRedisTemplate template;

    @GetMapping("/{name}")
    public void addToSet(@PathVariable String name) {
        this.template.opsForValue().set(KEY,name);
    }

    @GetMapping("/get")
    public Set<String> getKeyValues() {
        return this.template.opsForSet().members(KEY);
    }

}
//////////////////////////////////////////////////***********************************/////////



















