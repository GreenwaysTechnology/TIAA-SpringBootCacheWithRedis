Session Agenda:

1.Caching Abstraction && Implementation using Spring boot
2.Redis for caching,message bus,data base, streaming......


Caching:

What is cache / Caching?

In computing, a cache is a component that transparently stores data so that future requests
for that data can be served faster.

The data that is stored within a cache might be values that have been computed earlier or duplicates of original values that are stored elsewhere.

Before this, you need to understand one concept, called "IO".

IO - read and write.

Write:
  moving data into some place

Place:
 - In memory
 - Disk
 - Network Socket
 - Processors
 - External Storage devices.

IN Memory: Random access memory :RAM.
......................................
- Writing data into RAM.

Which is faster, but not durable.

Disk:
  -Writing data into hard disk.
Eg:
  file systems
     -Databases-RDBMS
Which is slow but durable.

Network Socket:
 -socket is entry and exit point of networks
 -apps write data into socket via os kernal, which intern transfer data to other machines 
  in the network.

-Processors
   you can store data inside cpu registers for faster access.

- External Storage devices
   -physical storage like pendrives,extrnal harddisk....
   -Cloud Storage.

Reading:
 -Reading requires more responsive- end user should able to get data very very faster.

Reads costs more when we talk to disk(file system,databases,remote storages) based data.

How to improve read performance?
................................

if any application / users reads the same data again and again, dont hit disk every time, rather make snapeshot of that data in first hit, keeps that "IN Memory(RAM) / CPU Register"
so that future requests served very faster : Caching

Real world examples:

 if application sends an sql query request to database engine.

-The database engine 
   -parses the query
   -Query Excution plan
   -Query will be compiled - binary image of that query
   -Query exection - Database engine will do sys call to disk
   -Read operation begins
   -Results are prepared
   -Send back to Client Applicaiton

imagine, if application repeats the same process again.

How to improve Network reads : WEB

If web clients ask some web documents such as html,pdf,image,json,xml to the webserver.

-webserver will do low level io calls-read

if web clients ask the same document again and again, we need to improve performance, so that 
HTTP protocals having feature called storing repeated content some where(IN Memory)-HTTP caching.
///////////////////////////////////////////////////////////////////////////////////////////

Hardwares :How to avoid reading data within hardware devices

-Hardware cache
A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average cost (time or energy) to access data from the main memory. A cache is a smaller, faster memory, located closer to a processor core, which stores copies of the data from frequently used main memory locations.
/////////////////////////////////////////////////////////////////////////////////////////////
             
          Caching is nothing but how to improve IO( Frequrent READ of same data) operation


Types of Caching:
................
Based on implemenentations

-hardward level caching
-software level caching
   -Disk cache -databases,filesystems....
   -Web cache - webservers,proxy servers, cdn
   -Memoization - Program level caching, to avoid code repationcycles(loop)
                  - languages -pythyon,groovy,javascript-most of the functional pl
   -Application level caching with caching components
         -Caching in Java Apps.
         -Spring framework abstracts away caching soultions in enterprise/micro services
          application.

-network level caching
   -protocal based caching-TCP
   -HTTP
   -SMTP.
............................................................................................

How to implement caching: Cache algorthims/Policy

caching is allabout io.

-write 
-read
-Replacement / Eviction.

Write Policys:
.............
 It defines how to interact with cache component/architecture, when application starts writing data.

1.Write Through
2.Write Around
3.Write Back


1.Write through pattern/policy:
...............................

1.When ever write request comes , write operation will be done in cache system.
2.From the Cache , data will be written to Database System.
3.Once Data is written in database successfully, acknowledgement will be sent to Client Application.

4.Application has to wait until the response come from cache(not suitable for blocking apps)
  (may be suitable for async /non blocking application).
5.It increases latency, since cache interacts with db,db interacts with cache and app.

2.Write around policy:
.......................

1.Applications write data to database directly
2.When read requests, Application hits Cache
3.If no data found in the cache first time, Cache loads data from Database into caching
  system
4.If data found in the cache , data will be returned from cache itself.

3.Write Back Policy:
...................

1.Application sends write requests to Cache System, once write is completed in Cache, Acknowledgement sent to Client Application.

There is background service, which starts writing data from Cache into Database Async

/////////////////////////////////////////////////////////////////////////////////////////

Read Policy:
...........
1.Cache Hit
2.Cache Miss


Cache Hit:
..........
Cache hit means the requested data already there in the cache.
This request can be served by simply reading the cache, which is comparatively faster
Hit happens , subsquent calls only, first time it wont happen.


Cache Miss:
...........

1.The data has to be recomputed or fetched from its original storage location

2.A cache miss occurs either
   2.1.Because the data was never placed in the cache,
   2.2 Because the data was removed (“evicted”) from the cache by either the caching system itself or an external application that specifically made that eviction request.

/////////////////////////////////////////////////////////////////////////////////////////////

Cache Replacement-Eviction Policy:
..................................

This is policy , implemented by cache providers in order to manage memory.

How to clear stale /unwanted /un used data from the cache system?
  This process of removing data from cache system is called "eviction".

How to evict?

-manual evication
-automatic evication.
  Systems like redis offers an alogorthims-TTL - Time to live.(how long data can be inside
  System, once timeout, data will be removed automatically.

In order to evit data from cache system, there are plent of algorthims.

1.Bélády's algorithm
2.First in first out (FIFO)
3.Last in first out (LIFO) or First in last out (FILO)
4.Least recently used (LRU)
5.Time aware least recently used (TLRU)
6.Most recently used (MRU)
8.Pseudo-LRU (PLRU)
9.Random replacement (RR)
10.Segmented LRU (SLRU)
12.Least-frequently used (LFU)
13.Least frequent recently used (LFRU)
14.LFU with dynamic aging (LFUDA)
15.Low inter-reference recency set (LIRS)
16.CLOCK-Pro
17.Adaptive replacement cache (ARC)
18.AdaptiveClimb (AC)
19.Clock with adaptive replacement (CAR)
20.Multi queue (MQ)
21.Pannier: Container-based caching algorithm for compound objects


Least recently used (LRU):
   Redis uses this alorthim.

////////////////////////////////////////////////////////////////////////////////////////////

Application Caching  Soultions and Implementation:
..................................................

Application caching provides, how to store data inside application.

Application caching can be classified into two types:
.....................................................

1.Local Cache
2.Distributed Cache

Both cache implementation will store data in side RAM Only.


1.Local Cache : (Cache System) 
 
 Cache is provided iniside application as "Data Structure".
 if you are working in java application , java provides a spec called jcache
JSR 107: JCACHE - Java Temporary Caching API

 IF you  are working in spring framework, Spring framework provides an abstraction
  "Caching Abstraction" : set of apis and annotations , developers start building caching system without worring about underlaying cache implemenation(systems-like memcache,redis,hazlecast....)


          "Cache data is maintained inside Application Process(JVM)"

Spring provides an data structure called "ConcurrentHashMapCache" 
  -it is map datastructure
  - used to store data inside app.



Note:

  In any caching system, data is stored in side data structure only : KEY-VALUE pair datastructure : Dictionary/HashMap/Map
   This is fundamental storage model of any caching system.
.............................................................................................

2.Distributed Cache /Data Grid

    Cache data is maintained outside application process(JVM).

///////////////////////////////////////////////////////////////////////////////////////////

Caching best practices:
.......................

Local Cache:
 -Part of application
 -easy to implement
 -very fast, no lantency.
-as application shuts down, no where data is persisted.
-it is diffcult in concurrency
-data cant be replicated
-heap size will increase , if you store more data.
-Avoid big heaps just for caching
-Big heap leads to long major GCs


Distributed Cache:
 -outside application process
 -it is easy to scale across clusters of nodes.
 -it is easy to make highly  available.
 -It is persisted-you can save data across time.
etc.......


Use a distributed cache for big amounts of data

Distributed caches implemented cache nodes.

Cache Nodes:

1.Hazelcast
2.Redis
3.memcached
4.Appache zoo keeper
5.Generic.
6.EhCache 2. x.
7.Infinispan
//////////////////////////////////////////////////////////////////////////////////////////////

Application Caching Implementation using Spring Boot caching Abstraction:
.........................................................................

1.Spring boot can support local and distributed cache providers
2.Spring boot offers abstraction apis to work with any cache providers without changing app
  code, you can switch any provider any time.
3.Spring boot uses cache starter packages.

Spring boot Caching Architecture:
.................................
     				       Application
				   (Caching Abstraction)
					   |
				      CacheManager
					   |
				---------------------------------- Cache Providers
				|  |   |  |                       |
	                       LocalCache / Distributed
				   |              |
			     ConcurrentHashMap	  Redis,MemCache,EHCach,Haelzcast......



Spring Application Setup and how to employ caching.
...................................................

Application Req:
 -It could be simple Databse CURD app
 -It could be complex microservice application.

App settings:

Lab Guide:

1.go to 
https://start.spring.io/

2.Add springweb,springdata,springcache dependencies

pom.xml

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-cache</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-jpa</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
  	     <dependency>
           	 <groupId>com.h2database</groupId>
            	<artifactId>h2</artifactId>
       	     </dependency>

2.create entity,Repository,Services,Rest End point.

Entity
Book.java
package com.example.entity;
import javax.persistence.*;
import java.io.Serializable;

@Entity
public class Book {
    @Id
    @GeneratedValue
    private long id;
    private String name;
    private String category;
    private String author;
    private String publisher;
    private String edition;

    public long getId() {
        return id;
    }

    public void setId(long id) {
        this.id = id;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public String getCategory() {
        return category;
    }

    public void setCategory(String category) {
        this.category = category;
    }

    public String getAuthor() {
        return author;
    }

    public void setAuthor(String author) {
        this.author = author;
    }

    public String getPublisher() {
        return publisher;
    }

    public void setPublisher(String publisher) {
        this.publisher = publisher;
    }

    public String getEdition() {
        return edition;
    }

    public void setEdition(String edition) {
        this.edition = edition;
    }

    @Override
    public String toString() {
        return "Book{" +
                "id=" + id +
                ", name='" + name + '\'' +
                ", category='" + category + '\'' +
                ", author='" + author + '\'' +
                ", publisher='" + publisher + '\'' +
                ", edition='" + edition + '\'' +
                '}';
    }
}
.........................................................................................

JPA implemenation:
.................

package com.example.repo;
import com.example.entity.Book;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Modifying;
import org.springframework.data.jpa.repository.Query;
import javax.transaction.Transactional;

public interface BookRepository extends JpaRepository<Book, Long> {
    @Transactional
    @Modifying
    @Query("update Book u set u.name=?2 where u.id=?1")
    int updateAddress(long id, String name);
}
........................................................................................

Service Implemenation:


package com.example.service;


import com.example.entity.Book;

public interface BookService {
    Book addBook(Book book);

    Book updateBook(Book book);

    Book getBook(long id);

    String deleteBook(long id);
}

package com.example.service;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.stereotype.Service;

import java.util.Optional;

@Service
public class BookServiceImpl implements BookService {

    private static final Logger logger = LoggerFactory.getLogger(BookServiceImpl.class);
    @Autowired
    private BookRepository bookRepository;

    @Override
    public Book addBook(Book book) {
        logger.info("adding book with id - {}", book.getId());
        return bookRepository.save(book);
    }


    @Override
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }

    @Override
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

    @Override
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
}
..........................................................................................

Controller

package com.example.api;

import com.example.entity.Book;
import com.example.service.BookService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.*;


@RestController
public class BooksController {

    @Autowired
    private BookService bookService;

    @PostMapping("/book")
    public Book addBook(@RequestBody Book book) {
        return bookService.addBook(book);
    }

    @PutMapping("/book")
    public Book updateBook(@RequestBody Book book) {
        return bookService.updateBook(book);
    }

    @GetMapping("/book/{id}")
    public Book getBook(@PathVariable long id) {
        return bookService.getBook(id);
    }

    @DeleteMapping("/book/{id}")
    public String deleteBook(@PathVariable long id) {
        return bookService.deleteBook(id);
    }
}
...........................................................................................
Main Application with Data:

package com.example;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;

@SpringBootApplication
public class MycacheAppApplication {

    public static void main(String[] args) {
        SpringApplication.run(MycacheAppApplication.class, args);
    }

    @Bean
    CommandLineRunner runner(BookRepository bookRepository) {
        return args -> {
            Book book = null;
            for (int i = 0; i < 10; i++) {
                book = new Book();
                book.setAuthor("Author " + i);
                book.setCategory("Caching " + i);
                book.setEdition(i + "nd edition ");
                book.setName("Caching in Action " + i);
                book.setPublisher("my Publisher " + i);
                bookRepository.save(book);
            }
            bookRepository.findAll().forEach(System.out::println);

        };
    }
}
/////////////////////////////////////////////////////////////////////////////////////

Test:
http://localhost:8080/book/1

you will get book information

{
id: 1,
name: "Caching in Action 0",
category: "Caching 0",
author: "Author 0",
publisher: "my Publisher 0",
edition: "0nd edition "
}

 browser-----controller----service---repo---db

Again if hit the same book,http://localhost:8080/book/1

The flow will go like above
///////////////////////////////////////////////////////////////////////////////////////////

Caching integration:
....................

Declarative Annotation-based Caching

For caching declaration, Spring’s caching abstraction provides a set of Java annotations:

@EnableCaching - Enable caching behaviour to the application

@Cacheable: Triggers cache population.

@CacheEvict: Triggers cache eviction.

@CachePut: Updates the cache without interfering with the method execution.

@Caching: Regroups multiple cache operations to be applied on a method.

@CacheConfig: Shares some common cache-related settings at class-level.
...........................................................................................


@EnableCaching - Enable caching behaviour to the application

-Can be added at top level- in the Main program or
-Can be created a separate Configuration file where you can add.

Spring Boot CacheProvider:
...........................

Hope you can understand how spring boot works-AutoConfiguration

Caching Auto-configuration
The Spring Boot Framework simplifies the implementation of caching by auto-configuration support. 

It searches for the libraries and configuration-files in the classpath and initializes the required dependency beans at the time of application startup

The auto-configuration of caching includes the following steps:
***************************************************************
1.Add the annotation @EnableCaching in the configuration file.
2.Add the required caching libraries in the classpath.

Where to start?

1.Setup Project and open Project.

2.Goto Spring boot - external libs--->spring.boot.autoconfigure--->spring factories--search---cache auto configuration-- select that--press Ctrl+N -->CacheAutoConfiguration.
Again
 goto
  org.springframework.boot.autoconfigure.cache.
   you can find cache providers informations...

Cache Properties:
Redis
 spring.cache.redis.timetolive
 spring.cache.redis.keyPrefix

How selects provider:
.....................

Spring Boot tries to detect the following providers (in this order):

1.Generic
2.EhCache 2.x
3.Hazelcast
4.Infinispan
5.JCache (JSR-107)
6.Redis
7.Guava
8.Simple

It is also possible to force the cache provider to use via the spring.cache.type property.
if you want to setup cache provider in application.properties or application.yaml

 spring.cache.type =provider


eg:
EhCache 2.x

<dependency>  
<groupId>org.ehcache</groupId>  
<artifactId>ehcache</artifactId>  
</dependency>  


EhCache 2.x is used if a file named ehcache.xml can be found at the root of the classpath. If EhCache 2.x and such file is present it is used to bootstrap the cache manager. An alternate configuration file can be provide a well using:

spring.cache.ehcache.config=classpath:config/another-config.xml

Simple
If none of these options worked out, a simple implementation using ConcurrentHashMap as cache store is configured. This is the default if no caching library is present in your application.

Note : default is jdk concurrentHashMap only.

///////////////////////////////////////////////////////////////////////////////////////////

How and where caching features are applied.
...........................................

 Caching features are added on top of biz apis - find,update,delete


At its core, the cache abstraction applies caching to Java methods, thus reducing the number of executions based on the information available in the cache.

That is, each time a targeted method is invoked, the abstraction applies a caching behavior that checks whether the method has been already executed for the given arguments.

If it has been executed, the cached result is returned without having to execute the actual method.

 If the method has not been executed, then it is executed, and the result is cached and returned to the user so that, the next time the method is invoked the cached result is returned.

This way, expensive methods (whether CPU- or IO-bound) can be executed only once for a given set of parameters and the result reused without having to actually execute the method again

The caching logic is applied transparently without any interference to the invoker.

"This approach works only for methods that are guaranteed to return the same output (result) for a given input (or arguments) no matter how many times it is executed."

........................................................................................

Annotations overview:
.....................

@Cachable:
As the name implies, you can use @Cacheable to demarcate methods that are cacheable 
-that is, methods for which the result is stored in the cache so that, on subsequent invocations (with the same arguments), the value in the cache is returned without having to actually execute the method.

parameterize it with the name of the cache where the results would be stored.

eg:
@Cacheable("books")
public Book findBook(ISBN isbn) {...}

The findBook() call will first check the cache books before actually invoking the method and then caching the result.

-In the preceding snippet, the findBook method is associated with the cache named books.

-Each time the method is called, the cache is checked to see whether the invocation has already been executed and does not have to be repeated.

-While in most cases, only one cache is declared, the annotation lets multiple names be specified so that more than one cache is being use.

-. In this case, each of the caches is checked before executing the method — if at least one cache is hit, the associated value is returned.

"

Eg:
    @Override
    //now this method will executed only if cache miss, if cache hit, method wont be executed
    @Cacheable("books")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(key,value);

Multiple cach names:
...................
The following example uses @Cacheable on the findBook method:

@Cacheable({"books", "isbns"})
public Book findBook(ISBN isbn) {...}

In this case, if any of the caches contains the required result, the result is returned and the method is not invoked.

eg:
    @Override
    @Cacheable(cacheNames = {"books", "isbns"})
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

////////////////////////////////////////////////////////////////////////////////////////////

How Spring boot sends cached data to Cache Provider? How data is indentified in caching?

-You need unique indentification.

Key-Value Store:

 All cache implementation uses , key-value stores internally.
 Each invocation of a cached method needs to be translated into a suitable key for cache  access

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(key,value);


KeyGenerator:

-This is responsible for generating every key for each data item in the cache, which would be used to lookup the data item on retrieval.

-The default implementation here is the SimpleKeyGenerator – which uses the method parameters provided to generate a key

The default key generator

By default, SimpleKeyGenerator in the org.springframework.cache.interceptor package, an implementation of KeyGenerator interface, is used to generate the cache key

SimpleKeyGenerator evaluates parameters of the cache annotated methods (by @Cachable, @CachePut and @CacheEvict). If only one non-null param is existing, it returns the param itself, otherwise the below SimpleKey's toString() method is used for computing all params

@Override
public String toString() {  
    return getClass().getSimpleName() + " [" + StringUtils.arrayToCommaDelimitedString(this.params) + "]";
}

Default Key Generation

The caching abstraction uses a simple KeyGenerator based on the following algorithm.

-If no params are given, return SimpleKey.EMPTY.

-If only one param is given, return that instance.

-If more than one param is given, return a SimpleKey that contains all parameters


   @Cacheable("books")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

ConcurrentHashMap books = new ConcurrentHashMap();
books.put(1,book);


Default Key Generation code

public class CustomKeyGenerator implements KeyGenerator {

 @Override
 public Object generate(Object target, Method method, Object...params) {
  return generateKey(params);
 }

 /**
  * Generate a key based on the specified parameters.
  */
 public static Object generateKey(Object...params) {
  if (params.length == 0) {
   return CustomCacheKey.EMPTY;
  }
  if (params.length == 1) {
   Object param = params[0];
   if (param != null && !param.getClass().isArray()) {
    return param;
   }
  }
  return new CustomCacheKey(params);
 }
}
////////////////////////////////////////////////////////////////////////////////////////////

/////////////////////////////////////////////////////////////////////////////////////////////

IS it Recommended to use default key generation ?

No!
Because it may cause unexpected key collisions.

Recommended use keys parameters:

The @Cacheable annotation lets you specify how the key
 is generated through its key attribute

@Cacheable(cacheNames="books", key="#isbn")
public Book findBook(ISBN isbn, boolean checkWarehouse, boolean includeUsed)

# - spring expression language syntax.
isbn - key reference. here we are using entire object as key.

Eg:

    @Cacheable(cacheNames = {"books"}, key = "#id")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }

Note:
ISBN isbn and key="#isbn" should match.

@Cacheable(cacheNames="books", key="#isbn.rawNumber")
public Book findBook(ISBN isbn, boolean checkWarehouse, boolean includeUsed)
Here we are taking isbn.rawNumber which is one of the field value for cache.

////////////////////////////////////////////*********************////////////////////////////

Conditional Based Caching:
..........................

Use case:
 What if i dont want to cache every thing i mean , i need to cache only few values 
based on some condtion.

The cache annotations support such functionality through the condition parameter, which takes a SpEL expression that is evaluated to either true or false.
If true, the method is cached. If not, it

@Cacheable(cacheNames="book", condition="#name.length() < 32") 
public Book findBook(String name)

//conditional : cache only books whose id greater than 5
    @Override
    @Cacheable(cacheNames = "books", condition = "#id>5 ")
    public Book getBook(long id) {
        logger.info("fetching book from db" + id);
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Multi threading and caching:

 if  a  method is by multiple thread of execution , there might be inconsistency in data reterival.


Synchronized caching

In a multi-threaded environment, certain operations might be concurrently invoked for the same argument (typically on startup). By default, the cache abstraction does not lock anything and the same value may be computed several times, defeating the purpose of caching.

For those particular cases, the sync attribute can be used to instruct the underlying cache provider to lock the cache entry while the value is being computed. As a result, only one thread will be busy computing the value while the others are blocked until the entry is updated in the cache.

@Cacheable(cacheNames="foos", sync=true)
public Foo executeExpensiveOperation(String id) {...}

This is an optional feature and your favorite cache library may not support it. All CacheManager implementations provided by the core framework support it. Check the documentation of your cache provider for more details.
////////////////////////////////////////////////////////////////////////////////////////////

How to update Cache?
....................

In order to avoid inconsistency between database and cache during data updates in the database.

When ever we update database, we need to update cache provider also.

                                      update cache as well
                                          |
 Client---------PUT------------api-----service---Repo---db

@CachePut:
-When the cache needs to be updated without interfering with the method execution, you can use the @CachePut annotation.


  @Override
    @CachePut(cacheNames = "books", key = "#book.id")
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }
/////////////////////////////////////////////////////////////////////////////////////////////
How to evit data from cache?
 -Via code
 -automatic

When ever we remove record from databse , we need to remove key from cache also.

                                      Delete from cache as well
                                          |
 Client---------DELTE------------api-----service---Repo---db

How to remove cache Entries?

@CacheEvict annotation:
.......................
The cache abstraction allows not just population of a cache store but also eviction

This process is useful for removing stale or unused data from the cache.

 Opposed to @Cacheable, annotation @CacheEvict demarcates methods that perform cache eviction, that is methods that act as triggers for removing data from the cache. 

Just like its sibling, @CacheEvict requires specifying one (or multiple) caches that are affected by the action, allows a custom cache and key resolution or a condition to be specified but in addition, features an extra parameter allEntries which indicates whether a cache-wide eviction needs to be performed rather then just an entry one (based on the key):

@CacheEvict(cacheNames="books", allEntries=true)
public void loadBooks(InputStream batch)


    @Override
    @CacheEvict(cacheNames = "books", key = "#id" ,allEntries = true)
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
////////////////////////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////////////////

@Caching:

Use case , what if i want to apply different caching on single method
like having two different CacheEvit Policy.

Sometimes, multiple annotations of the same type (such as @CacheEvict or @CachePut) need to be specified — for example, because the condition or the key expression is different between different caches. @Caching lets multiple nested @Cacheable, @CachePut, and @CacheEvict annotations be used on the same method. The following example uses two @CacheEvict annotations


@Caching(evict = { @CacheEvict("primary"), @CacheEvict(cacheNames="secondary", key="#p0") })
public Book importBooks(String deposit, Date date)

//////////////////////////////////////////////////////////////////////////////////////////

@CacheConfig annotation

So far we have seen that caching operations offered many customization options and these can be set on an operation basis. 

However, some of the customization options can be tedious to configure if they apply to all operations of the class. For instance, specifying the name of the cache to use for every cache operation of the class could be replaced by a single class-level definition.
This is where @CacheConfig comes into play.

@CacheConfig("books")
public class BookRepositoryImpl implements BookRepository {

    @Cacheable
    public Book findBook(ISBN isbn) {...}
}

eg:
package com.example.service;

import com.example.entity.Book;
import com.example.repo.BookRepository;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cache.annotation.CacheConfig;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.cache.annotation.CachePut;
import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Service;

import java.util.Optional;

@Service
@CacheConfig(cacheNames = "books")
public class BookServiceImpl implements BookService {

    private static final Logger logger = LoggerFactory.getLogger(BookServiceImpl.class);
    @Autowired
    private BookRepository bookRepository;

    @Override
    public Book addBook(Book book) {
        logger.info("adding book with id - {}", book.getId());
        return bookRepository.save(book);
    }


    @Override
    @CachePut(key = "#book.id")
    public Book updateBook(Book book) {
        bookRepository.updateAddress(book.getId(), book.getName());
        logger.info("book updated with new name");
        return book;
    }

    //   @Override
    //now this method will executed only if cache miss, if cache hit, method wont be executed
//    @Cacheable(cacheNames = {"books", "isbns"})
//    public Book getBook(long id) {
//        logger.info("fetching book from db");
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

    @Override
    @Cacheable(key = "#id")
    public Book getBook(long id) {
        logger.info("fetching book from db");
        Optional<Book> book = bookRepository.findById(id);
        if (book.isPresent()) {
            return book.get();
        } else {
            return new Book();
        }
    }
    //conditional : cache only books whose id greater than 5
//    @Override
//    @Cacheable(cacheNames = "books", condition = "#id>5 ")
//    public Book getBook(long id) {
//        logger.info("fetching book from db" + id);
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

//    @Override
//    @Cacheable(cacheNames = "books",  unless = "#id==3")
//    public Book getBook(long id) {
//        logger.info("fetching book from db" + id);
//        Optional<Book> book = bookRepository.findById(id);
//        if (book.isPresent()) {
//            return book.get();
//        } else {
//            return new Book();
//        }
//    }

    @Override
    @CacheEvict(key = "#id", allEntries = true)
    public String deleteBook(long id) {
        bookRepository.deleteById(id);
        return "Book deleted";
    }
}
//////////////////////////////////////////////////////////////////////////////////////////////

                                         Redis


What Redis Stands For?

  Remote Dictionary Server.

History of Redis:

 Redis was developed by a developer Salvatore Sanfilippo, who released on May 10, 2009.

What is Redis?
  Redis is an in-memory data structure store, used as a distributed, in-memory key–value database, cache ,message broker.

in-memory : 
   Data is stored in RAM.

Distributed
   Data can be replicated across multiple instances of process(redis).

database:
  The place where we can store data.

Use cases of Redis:

-Distributed Enterprise cache system.
-Message broker - like RabitMQ,Kaffa
-Used as NoSql database.

///////////////////////////////////////////////////////////////////////////////////////////

Redis as NoSql Database:
........................

Data Storage Models:

-File system
-DBMS
-RDBMS- Based Relational Algerba theory proposed by Dr.Codd
IBM invented a language to talk to RDBMS - SQL

-Storing data in the form of tables.
 which is structure which stores data in the row-colum 

 row defins data

 column defines indentifier for data.

 column
 |
 id    username   password 
 1      admin      root  -row

In RDBMS, data is grouped under tables,views- database objects.
Database objects are groued under one object called schema(database).
Many schemas can be groued inside a process -  Database Instance.

RDBMS has been good for lot of use case for more than 4 decades, after 2005,many biz uses
cases required different data models.

RDBMS Drawbacks:

1.Properity Solution
  Like Oracle,IBM,SQL Server - Single vendor
2.Fixed schema objects
   once table is designed, after adding huge amount of data, if you want to add new column /
   delete column.
3.Open source soultions

4.Dynamic raw data.
   i want to store comments ,ratings about the particular product.

Birth of NOSQL:

 -Open source soultions
 -Dynamic schema
***********************************************XXXXXXXXX**********************************
Types of NOSQL Databases:
........................

 column
 |
 id    username   password 
 1      admin      root  -row

id is column
username is column
password is column.
1 value
admin value
root value

Different kind of data models in NoSQL are : 
- Key-Value
- Document 
- Column Family
- Graph 

Key-Value:
...........

 ->It is one of the data structure 
    ->Dictionary
    ->Map

Data Structure :
   Store data using some structure.

eg:
   int id=1
   String userName="admin"
   String password ="root"
 
 Single Dimension:

  User [] users = {new User(),new User()}
  List<User> users= Arrays.asList(new User(),new User())
 Two dimension:
    key,value
  HashMap map = new HashMap();
  map.put("id",1)
  map.put("name","admin") - key-value
 
    
Relational model to Key-Value:
..............................

1.in relational model data is indentified by primary key.


  id - 1 ----- user name - vlaue  pass word -value. - row

2.collection of data is indentied by table name

  users
   id    username   password 
   1      admin      root 
   2      root       super

how to read data
   users.id ---> 
 select id,username,password from users where id=1
.........................................................................................

 objectname:identifier:column

eg:
      
          key         value
           |
     users:1:id         1
     users:1:username  admin
     users:1:password  root

     users:2:id        2
     users:2:username  root
     users:2:password  super

     users:3:id        3
     users:3:username  subu
     users:3:password  foo
     users:3:otp       ""

 read data

     $>users:3:otp
     12345
    
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

Document Oriented Data Model:
...............................

Data is stored inside datastore as document.

Document is collection of data.

Document can be any thing.

Types of document

1.structure document
2.unstructure document.

structure document has some structures.

-SGML
-HTML
Data oriented documents
-XML
-JSON
-Properties
-YAML

JSON
{
    "FirstName": "Bob", 
    "Address": "5 Oak St.", 
    "Hobby": "sailing"
}

XML
<contact>
    <firstname>Bob</firstname>
    <lastname>Smith</lastname>
    <phone type="Cell">(123) 555-0178</phone>
    <phone type="Work">(890) 555-0133</phone>
    <address>
      <type>Home</type>
      <street1>123 Back St.</street1>
      <city>Boys</city>
      <state>AR</state>
      <zip>32225</zip>
      <country>US</country>
    </address>
  </contact>

How to store document into database?
 Birth of document oriented

Mongodb
...........................................................................................

Column-Family:
..............

 {
   12345: {
     profile:{}
     orders:{}

   }
     
 }

 invoice:1234:profile   id 1 name xxx address xxx
///////////////////////////////////////////////////////////////////////////////////////////

Graph database:

 collection of inter connected nodes , each node defines its own data.

Neo4j:
............................................................................................

Redis Architecture:
...................

->Redis is written in c language.
->Redis has been distributed to various platforms
->Redis is distributed in two flavours
  -Open Source
     redis.io
  -Commerical
    https://redislabs.com/

->Redis is distributed to BSD,linux operating systems only, no windows distribution.
  -How to use redis on windows
     ->Via VM - inside vm , you can have linux
     ->Via docker easy to use.
     ->Via windows Linux subsystem.


->Redis supports non blocking /Async arch
   Linux provides kernal lib called - epoll



suppose if you are using on linux

 -source code distribution

 -installer - not recommended


Redis storage Model:

-Redis stores data in mememory -RAM , it never stores data in disk.
-Redis is the first fastest INMEMORY data Store.
-Redis stores data in the form of "Key-Value" Pair Model.
-Redis is powered by "Data Structures"

Data Structure Supported by Redis:
..................................
 Dictionary
    key -value

When you define key, you can tell the data type of key.

When you define value, value type must be defined.

Value Types:
............
1.String
2.List
3.Hash
4.Set
5.SortedSet
6.bitMap
7.hyperloglog
8.Geospatial

Value types define, how many values can be stored in a single given key.

eg:
   key              value

   id                1        -Single value /Scallar

   name             Subramanian  -Single value /scallar

   skills           java,redis,microservices  ---- List of values - List  

   address          street:'10thstreet',city:'Coimbatore'  -Hash

   hitcount         1,2,1,2,3,3,4,5,6 -> 1,2,3,4,5,6   -Set - Like List without duplicates

   sequences        34,1,2,5,5,3,2 -> 1,2,3,5,34   -Sorted Set - Like List without duplicates                                                                 + sorting
  
////////////////////////////////////////////////////////////////////////////////////////////

Redis features:

1.for development
 how to store ,reterive, process datas
 datatypes
 commands
 pipelining
 transactions
 pub-sub pattern- message broker
 scripting -lua scripting -- plsql


2.for adminstrations
-how to start server in standalone.
-how to start server in master-replica - scalability - distributed
-how to start server in master-replicat with highavailablity - clusters,sentinals
-security - acl,ssl...
-Monitoring
  -memory manangement
  -client management
  -health managment
-configuration
   -many configurations details
-Persistency.


3.How to extend redis core functionality.
  
Redis allows to add more features apart from core redis distribution.

Redis modules:
  plugable code, can be added to enchance redis

eg:
 can i store json document into redis?
   No
 but is possible via redis modules.

Popular Modules:

1.RedisSearch
2.RedisJson
3.RedisGraph
4.RedisTimeSeries
//////////////////////////////////////////////////////////////////////////////////////////////

Redis components:

1.Redis Server

  Provided by redis.io/redis labs

2.Redis Clients
 Most of the programming languages supports client libs

Java:
-Jedis
-lettuce
-Spring provides spring-data-redis - which runs on either jedis,lettuce

CommandLine clients:
 redis-cli ; cli tool for testing and prototyping , administration...

////////////////////////////////////////////////////////////////////////////////////////////

Lets Program with Redis:
.......................

Setup:
......

1.Using docker.

 docker run -–name redis -p 6379:6379 redis

The default port ; 6379.

Redis where stores data.
 inside database.

Redis process supports by default 16 databases,each database is named by number like 0...15
database[0]>

How to run redis-cli?

docker exec -it redis redis-cli
 
////////////////////////////////////////////////////////////////////////////////////////////

Rediscli is client which communicates redis server via "RedisProtocol"

In RDBMS , Database clients send request, and server returns response.

request could be "Commands" - SQL commands 
 -DDL  - create,grant,revoke\ 
 -DML   - Select,insert,update
 -DCL   - commit,set save point

response would be , rows,or error,no of rows affected...

IN Redis
  Clients will send Commands , server will return response.

Redis offers lot of commands based on datatype,administration,utitlity category.

How to test server is working or not? : health checking.

127.0.0.1:6379> ping
PONG
127.0.0.1:6379> ping "Hello Redis!"
"Hello Redis!"
127.0.0.1:6379>

How to get Server info?

127.0.0.1:6379> INFO
# Server
redis_version:6.0.4
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:d5d470262d47f1a0
redis_mode:standalone
os:Linux 4.19.121-linuxkit x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:1
run_id:84ea3a2dc0e6a9606b54cc39f906803e7d22a027
tcp_port:6379
uptime_in_seconds:368
uptime_in_days:0
hz:10
configured_hz:10
lru_clock:14188345
executable:/data/redis-server
config_file:

# Clients
connected_clients:2
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:0
tracking_clients:0
clients_in_timeout_table:0

# Memory
used_memory:887288
used_memory_human:866.49K
used_memory_rss:7561216
used_memory_rss_human:7.21M
used_memory_peak:887288
used_memory_peak_human:866.49K
used_memory_peak_perc:100.00%
used_memory_overhead:836820
used_memory_startup:802848
used_memory_dataset:50468
used_memory_dataset_perc:59.77%
allocator_allocated:1178984
allocator_active:1433600
allocator_resident:3796992
total_system_memory:2085830656
total_system_memory_human:1.94G
used_memory_lua:37888
used_memory_lua_human:37.00K
used_memory_scripts:0
used_memory_scripts_human:0B
number_of_cached_scripts:0
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
allocator_frag_ratio:1.22
allocator_frag_bytes:254616
allocator_rss_ratio:2.65
allocator_rss_bytes:2363392
rss_overhead_ratio:1.99
rss_overhead_bytes:3764224
mem_fragmentation_ratio:8.95
mem_fragmentation_bytes:6716440
mem_not_counted_for_evict:0
mem_replication_backlog:0
mem_clients_slaves:0
mem_clients_normal:33972
mem_aof_buffer:0
mem_allocator:jemalloc-5.1.0
active_defrag_running:0
lazyfree_pending_objects:0

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1608023497
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:-1
rdb_current_bgsave_time_sec:-1
rdb_last_cow_size:0
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
module_fork_in_progress:0
module_fork_last_cow_size:0

# Stats
total_connections_received:2
total_commands_processed:7
instantaneous_ops_per_sec:0
total_net_input_bytes:137
total_net_output_bytes:47490
instantaneous_input_kbps:0.00
instantaneous_output_kbps:0.00
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
expired_stale_perc:0.00
expired_time_cap_reached_count:0
expire_cycle_cpu_milliseconds:3
evicted_keys:0
keyspace_hits:0
keyspace_misses:0
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:0
migrate_cached_sockets:0
slave_expires_tracked_keys:0
active_defrag_hits:0
active_defrag_misses:0
active_defrag_key_hits:0
active_defrag_key_misses:0
tracking_total_keys:0
tracking_total_items:0
tracking_total_prefixes:0
unexpected_error_replies:0

# Replication
role:master
connected_slaves:0
master_replid:7b14ce66bea6d5afd8ceb2942cc144359e218c36
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:0.162191
used_cpu_user:0.153654
used_cpu_sys_children:0.001343
used_cpu_user_children:0.001118

# Modules

# Cluster
cluster_enabled:0

# Keyspace
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////

How to save simple data into redis server?

Command:
SET 
GET

SET key value [EX seconds|PX milliseconds|KEEPTTL] [NX|XX] [GET]

127.0.0.1:6379> SET message "Hello Redis!!"
OK

Here We send key via set command to server, server will execute that command, stores data with
key-value, once success it returns RESPONSE - OK.

GET key

127.0.0.1:6379> GET message
"Hello Redis!!"
/////////////////////////////////////////////////////////////////////////////////////////////

Commands: Keys:
..............

How to read all keys or some of the keys?

 KEYS
 SCAN

1.KEYS pattern

Returns all keys matching pattern.

127.0.0.1:6379> KEYS *
1) "message"

127.0.0.1:6379> KEYS m?ssage
1) "message"

Redis uses glob-style pattern similar to regex pattern.

Keys
-Blocks until complete
   lets say database contains million keys, it blocks database long time
 Recommendation : dont use in production, use it in dev and testing env only.

Scan :
  iterates over cursor
  it also blocks but only iterates over handful  of keys at  the time.
  Returns slot references
  May return 0 or more keys per call.
  Safe for production.



127.0.0.1:6379> scan 0 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 0 MATCH *
1) "15"
2)  1) "a"
    2) "c1"
    3) "c"
    4) "d"
    5) "d1"
    6) "b"
    7) "message"
    8) "e"
    9) "a1"
   10) "e1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379> scan 14 MATCH * COUNT 4
1) "9"
2) 1) "d1"
   2) "b"
   3) "message"
   4) "e"
127.0.0.1:6379> scan 9 MATCH * COUNT 4
1) "0"
2) 1) "a1"
   2) "e1"
   3) "b1"
127.0.0.1:6379> scan 0 MATCH * COUNT 4
1) "14"
2) 1) "a"
   2) "c1"
   3) "c"
   4) "d"
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////
Redis Key Modeling Patterns: Redis community Recommendation:
............................................................

KEY NAME:

Plain keynames
   A    10
   X    20
   name "subramanian"

Redis coding standard:
  objectname:identifier:subidentifier

i want to store order status

  order:1  available
  order:2  outofstock
  order:3  pending
  user:1:status online

127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> SET order:1 "available"
OK
127.0.0.1:6379> get order:2 "outofstock"
OK
127.0.0.1:6379> set user:1:status online
OK
127.0.0.1:6379> set user:2:status online
OK
127.0.0.1:6379> set user:3:status offline

////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////////

KEYS REMOVAL: DEL and Unlink
/////////////////////////////


DEL key [key ...]

Removes the specified keys. A key is ignored if it does not exist.

Return value
Integer reply: The number of keys that were removed.

-The DEL Command will remove the key and memory associated with the key.
-This is performed as a blocking opertion.

UnLink:
......
-With UNLINK, key is unlinked , hence the name of the  command and will no longer exists.
-The memory associated with the key value is reclaimed by an asynchronous process,so the UNLINK is a  non-blocking command.


127.0.0.1:6379> DEL a
(integer) 1
127.0.0.1:6379> DEL a a1
(integer) 1
127.0.0.1:6379> DEL b b1
(integer) 2
127.0.0.1:6379> UNLINK  c c1
(integer) 2
127.0.0.1:6379> get c
(nil)
127.0.0.1:6379> get a
(nil)
127.0.0.1:6379>

Note:
 if key does not exit , it returns "nil"

///////////////////////////////////////////////////////////////////////////////////////////

//////////////////////////////////////////////////////////////////////////////////////////////////////

However, there are times when you only want to set the value if the key already exists.

EXISTS key [key ...]

EXISTS customer:1000
127.0.0.1:6379> EXISTS customer:2000
(integer) 1
127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379>

it returns 1 for key present , 0 means no key present

Use case :

Why should i use exits command to verify the existing of key.

Operations:
 - new Key - insert
 - update key  -  update.

how to add new key

-SET Command
127.0.0.1:6379> SET customer:9000 jane
OK
127.0.0.1:6379> GET customer:9000
"jane"

what if i want to update customer name of customer:9000
SET Command

127.0.0.1:6379> SET customer:9000 "jane james"
OK
127.0.0.1:6379> GET customer:9000
"jane james"
127.0.0.1:6379>



127.0.0.1:6379> EXISTS customer:9000
(integer) 0
127.0.0.1:6379> SET customer:9000 jane
OK

You could first check with the exist command to see if the key is present before using SET.

But having two operations-- the exists followed by a set--means two round trips Redis and possible inconsistencies between the operations.

NX -  for create
XX -  for update.

127.0.0.1:6379> SET customer:333 john NX
OK
127.0.0.1:6379> SET customer:333 john NX
(nil)
127.0.0.1:6379> SET customer:444 Karthik XX
(nil)
127.0.0.1:6379> SET customer:444 Karthik NX
OK
127.0.0.1:6379> SET customer:444 Karthik.K XX
OK
127.0.0.1:6379> GET customer:444
"Karthik.K"
127.0.0.1:6379>

/////////////////////////////////////////////////////////////////////////////////////////////

Timers : Automatic Key Eviction:
.................................
timeout in sec- ex
timeout in msc -px
	
27.0.0.1:6379> SET seat-hold Row:A:Seat:4 EX 5000
OK
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> get seat-hold
"Row:A:Seat:4"
127.0.0.1:6379> TTL seat-hold
(integer) 4957
127.0.0.1:6379> TTL seat-hold
(integer) 4952
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> TTL user:password
(integer) -2
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379> exists user:password
(integer) 0
127.0.0.1:6379> SET user:password something PX 10000
OK
127.0.0.1:6379> exists user:password
(integer) 1
127.0.0.1:6379> get user:password
"something"
127.0.0.1:6379> get user:password
(nil)
127.0.0.1:6379>
//////////////////////////////////////////////////////////////////////////////////////////////

                                             Data types
1.String:
 -store alphabets
 -store numbers
 -store binary.
    -image,spreadsheets,html fragments

no int,float datatype.

There is a limit of 512 megabytes for any string value

JPEGs, Excel spreadsheets, HTML fragments, as well as
plain old regular text and numbers are permissible.

Internally, Redis stores encoding of the value, stores a knowledge of whether it is a text, number, or binary.
 1 - integer
 "a" - string
 binary - bytes

How to know the type of key?

TYPE key

127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string

Since string is Super Type, 10 also stored as string but it is numeric value.

Can i do some computation on numerical value.
Yes!

in order to know the internal type of string

OBJECT subcommand key

The OBJECT command allows to inspect the internals of Redis Objects associated with keys

OBJECT ENCODING <key> returns the kind of internal representation used in order to store the value associated with a key.

127.0.0.1:6379> SET  a 10
OK
127.0.0.1:6379> SET name "Subramanian"
OK
127.0.0.1:6379> SET b "10"
OK
127.0.0.1:6379> TYPE a
string
127.0.0.1:6379> TYPE name
string
127.0.0.1:6379> TYPE b
string
127.0.0.1:6379> SET c 10.5
OK
127.0.0.1:6379> TYPE c
string
127.0.0.1:6379> INCR a
(integer) 11
127.0.0.1:6379> INCR b
(integer) 11
127.0.0.1:6379> OBJECT ENCODING a
"int"
127.0.0.1:6379> OBJECT ENCODING b
"int"
127.0.0.1:6379> OBJECT ENCODING name
"embstr"
127.0.0.1:6379> OBJECT ENCODING c
"embstr"
127.0.0.1:6379> INCR name
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCR c
(error) ERR value is not an integer or out of range
127.0.0.1:6379> INCRBYFLOAT c
(error) ERR wrong number of arguments for 'incrbyfloat' command
127.0.0.1:6379> INCRBYFLOAT c 1
"11.5"
127.0.0.1:6379> INCRBYFLOAT c 1
"12.5"
127.0.0.1:6379> INCRBY a 10
(integer) 21
127.0.0.1:6379> INCRBY a 10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> INCRBY a 10
(integer) 41
127.0.0.1:6379> INCRBY a -10
(integer) 31
127.0.0.1:6379> DECR a
(integer) 30
127.0.0.1:6379> DECRby a 5
(integer) 25
127.0.0.1:6379> DECRby a 5
(integer) 20
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

String operations:

-string length
-stringrange
-append

127.0.0.1:6379> STRLEN name
(integer) 11
127.0.0.1:6379> set name "Subramanian"
OK
127.0.0.1:6379> GETRANGE name 0 4
"Subra"
127.0.0.1:6379>

127.0.0.1:6379> APPEND name "Murugan"
(integer) 18
127.0.0.1:6379> get name
"SubramanianMurugan"
127.0.0.1:6379>
////////////////////////////////////////////////////////////////////////////////////////////

Streo type commands:

 -Commands looks like but which gives semantic meaning and simple use to

MSET key value [key value ...]
////////////////////////////////////////////////////////////////////////////////////////////

Bit Maps:
........

Collection of bits which forms a structure called bit map.

BitMaps are  a data type used within Redis and represents a long list of bits that contain 0 by default and we can use SETBIT Command to flip to 1 or 0


Key                    Value                               type
	
a_bitmap     0 0 0  0 0 0 0 0 0 0 0 0 0 0                  binary string


bitmap can store up to 2pow 32 bits,about 4 billion items

Use case: login use case

SETBIT logins:2017:04 6 1

here login:2017:04 is key
6 is offset , typically userid as offset
1 is active bit

SETBIT logins:2017:04 6 1

27.0.0.1:6379> SET login:today 7 1
(error) ERR syntax error
127.0.0.1:6379> SETBIT login:today 7 1
(integer) 0
127.0.0.1:6379> SETBIT login:today 7 0
(integer) 1
127.0.0.1:6379> GET login:today
"\x00"
127.0.0.1:6379> Type login:today
string
127.0.0.1:6379> object encoding login:today
"raw"
127.0.0.1:6379>

types:
 int -numbers
 embstr -embededstring
 raw - binary- bits
/////////////////////////////////////////////**************//////////////////////////////////





























































